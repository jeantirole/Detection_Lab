{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from albumentations import *\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from glob import glob\n",
    "import utils_rs\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm \n",
    "\n",
    "import wandb\n",
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class building_dataset():\n",
    "    def __init__(self, img_dir,mask_dir, phase):\n",
    "        self.phase = phase\n",
    "\n",
    "        self.image_files = sorted(glob( os.path.join( img_dir , \"*.png\")) )\n",
    "        self.mask_files  = sorted(glob( os.path.join( mask_dir , \"*.png\")))\n",
    "\n",
    "        assert len(self.image_files) == len(self.mask_files)\n",
    "\n",
    "        self.IMAGE_SIZE = 224 #224 => 250\n",
    "\n",
    "        self.ISAID_PALETTE = {\n",
    "            0: (0, 0, 0), 1: (0, 0, 63), 2: (0, 63, 63), 3: (0, 63, 0), 4: (0, 63, 127),\n",
    "            5: (0, 63, 191), 6: (0, 63, 255), 7: (0, 127, 63), 8: (0, 127, 127),\n",
    "            9: (0, 0, 127), 10: (0, 0, 191), 11: (0, 0, 255), 12: (0, 191, 127),\n",
    "            13: (0, 127, 191), 14: (0, 127, 255), 15: (0, 100, 155)}\n",
    "\n",
    "        self.ISAID_CLASSES = ('background', 'ship', 'store_tank', 'baseball_diamond',\n",
    "            'tennis_court', 'basketball_court', 'Ground_Track_Field',\n",
    "            'Bridge', 'Large_Vehicle', 'Small_Vehicle', 'Helicopter',\n",
    "            'Swimming_pool', 'Roundabout', 'Soccer_ball_field', 'plane',\n",
    "            'Harbor')\n",
    "        \n",
    "        self.trans_ = Compose([\n",
    "                # affine\n",
    "                VerticalFlip(p=0.8),\n",
    "                HorizontalFlip(p=0.8),\n",
    "                RandomRotate90(p=0.8),\n",
    "                #RandomBrightnessContrast(p=0.5),\n",
    "                ])\n",
    "        \n",
    "        self.trans_normalizer  = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def build_transformer_normalize(self):\n",
    "      transformer = transforms.Compose([\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "      ])\n",
    "      return transformer\n",
    "\n",
    "    def convert_to_target_(self, mask_image, IMAGE_SIZE):\n",
    "        #print(mask_image.shape)\n",
    "        mask_image = np.asarray(mask_image)\n",
    "\n",
    "        canvas = np.zeros( (mask_image.shape[0],mask_image.shape[1]) ,  dtype=np.uint8)\n",
    "        for k,v in self.ISAID_PALETTE.items():\n",
    "            canvas[np.all(mask_image == v, axis=-1)] = k\n",
    "\n",
    "        #-------\n",
    "        #mask = np.argmax(canvas, axis=-1 )\n",
    "        #print(canvas.shape)\n",
    "\n",
    "        return canvas\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # image\n",
    "        image = cv2.imread( self.image_files[index] )\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, dsize=(self.IMAGE_SIZE,self.IMAGE_SIZE), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # mask\n",
    "        mask = cv2.imread( self.mask_files[index] )\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.resize(mask, dsize=(self.IMAGE_SIZE,self.IMAGE_SIZE), interpolation=cv2.INTER_NEAREST) # inter nearest\n",
    "        \n",
    "        # build normalize\n",
    "        normalizer = self.trans_normalizer\n",
    "\n",
    "        if self.phase=='train':\n",
    "            \n",
    "            # aug \n",
    "            augmented = self.trans_(image=image,mask=mask)\n",
    "            image= augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "            # processing \n",
    "            image = normalizer(image)\n",
    "            mask = self.convert_to_target_(mask, self.IMAGE_SIZE)\n",
    "            mask = torch.from_numpy(mask).long()\n",
    "            \n",
    "            return image, mask\n",
    "    \n",
    "        elif self.phase=='val':\n",
    "          # normalize validation 할 때는 그냥 normalize 빼보자\n",
    "           image = normalizer(image)\n",
    "\n",
    "           mask = self.convert_to_target_2(mask_image, self.IMAGE_SIZE)\n",
    "           target = torch.from_numpy(mask).long()\n",
    "           return image, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for a, b in batch:\n",
    "        \n",
    "        images.append(a)\n",
    "        targets.append(b)\n",
    "    images = torch.stack(images, dim=0)\n",
    "    targets = torch.stack(targets, dim=0)\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/01.Models/04.SAM_fine/0.data/01.512_imgs\"\n",
    "mask_path = \"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/01.Models/04.SAM_fine/0.data/02.512_masks\"\n",
    "\n",
    "tr_dataset = building_dataset(img_dir=img_path, mask_dir=mask_path, phase=\"train\")\n",
    "val_dataset = building_dataset(img_dir=img_path,mask_dir=mask_path, phase=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"resnet152\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=16,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tr_dataset.__getitem__(0)[0]\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "target = tr_dataset.__getitem__(0)[1]\n",
    "target = target.unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "pred = model(img)\n",
    "\n",
    "loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "output_ = loss(pred,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8170, grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_metric():\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.CE_loss = nn.CrossEntropyLoss(reduction=\"mean\") # \"mean\" or \"sum\"\n",
    "\n",
    "    def __call__(self, pred, target):\n",
    "        # cross-entropy\n",
    "        loss1 = self.CE_loss(pred, target)\n",
    "        \n",
    "        # dice-coefficient\n",
    "        onehot_pred = F.one_hot(torch.argmax(pred, dim=1), num_classes=self.num_classes).permute(0, 3, 1, 2) \n",
    "        onehot_target = F.one_hot(target, num_classes=self.num_classes).permute(0, 3, 1, 2)\n",
    "        loss2 = self._get_dice_loss(onehot_pred, onehot_target)\n",
    "        \n",
    "        # total loss\n",
    "        total_loss = loss1 + loss2\n",
    "\n",
    "        # dice score\n",
    "        # dice_coefficient = self._get_batch_dice_coefficient(onehot_pred, onehot_target)\n",
    "        return total_loss\n",
    "\n",
    "    def _get_dice_coeffient(self, pred, target):\n",
    "        set_inter = torch.dot(pred.reshape(-1).float(), target.reshape(-1).float())\n",
    "        set_sum = pred.sum() + target.sum()\n",
    "        if set_sum.item() == 0:\n",
    "            set_sum = 2 * set_inter\n",
    "        dice_coeff = (2 * set_inter) / (set_sum + 1e-9)\n",
    "        return dice_coeff\n",
    "\n",
    "    def _get_multiclass_dice_coefficient(self, pred, target):\n",
    "        dice = 0\n",
    "        for class_index in range(1, self.num_classes):\n",
    "            dice += self._get_dice_coeffient(pred[class_index], target[class_index])\n",
    "        return dice / (self.num_classes - 1)\n",
    "\n",
    "    def _get_batch_dice_coefficient(self, pred, target):\n",
    "        num_batch = pred.shape[0]\n",
    "        dice = 0\n",
    "        for batch_index in range(num_batch):\n",
    "            dice += self._get_multiclass_dice_coefficient(pred[batch_index], target[batch_index])\n",
    "        return dice / num_batch\n",
    "\n",
    "    def _get_dice_loss(self, pred, target):\n",
    "        return 1 - self._get_batch_dice_coefficient(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_metric = UNet_metric(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.8170, grad_fn=<AddBackward0>), tensor(0.))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_metric( pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- args\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "\n",
    "#-- logger\n",
    "logging.basicConfig(filename='./01.log/model_v1.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#-- datasets \n",
    "train_dataset = building_dataset(img_dir=img_path, mask_dir=mask_path, phase=\"train\" )\n",
    "train_loader  = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataset = building_dataset(img_dir=img_path,mask_dir=mask_path, phase=\"val\" )\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "data_loader= {}\n",
    "data_loader[\"train\"] = train_loader\n",
    "data_loader[\"valid\"] = valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7381"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7380.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob(os.path.join(img_path,\"*.png\"))) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 , iter : 0 , total_iter : 3691 , running_loss : 3.0274264812469482\n",
      "epoch : 0 , iter : 100 , total_iter : 3691 , running_loss : 2.888401376138819\n",
      "epoch : 0 , iter : 200 , total_iter : 3691 , running_loss : 2.7335412431119095\n",
      "epoch : 0 , iter : 300 , total_iter : 3691 , running_loss : 2.53403531990178\n",
      "epoch : 0 , iter : 400 , total_iter : 3691 , running_loss : 2.3427370724238066\n",
      "epoch : 0 , iter : 500 , total_iter : 3691 , running_loss : 2.1750047214016943\n",
      "epoch : 0 , iter : 600 , total_iter : 3691 , running_loss : 2.0314430680727207\n",
      "epoch : 0 , iter : 700 , total_iter : 3691 , running_loss : 1.9096435046570108\n",
      "epoch : 0 , iter : 800 , total_iter : 3691 , running_loss : 1.8031475929434082\n",
      "epoch : 0 , iter : 900 , total_iter : 3691 , running_loss : 1.7076176323583732\n",
      "epoch : 0 , iter : 1000 , total_iter : 3691 , running_loss : 1.6232063040866718\n",
      "epoch : 0 , iter : 1100 , total_iter : 3691 , running_loss : 1.547762386480534\n",
      "epoch : 0 , iter : 1200 , total_iter : 3691 , running_loss : 1.4789068797645124\n",
      "epoch : 0 , iter : 1300 , total_iter : 3691 , running_loss : 1.4168130219395028\n",
      "epoch : 0 , iter : 1400 , total_iter : 3691 , running_loss : 1.3583828877288049\n",
      "epoch : 0 , iter : 1500 , total_iter : 3691 , running_loss : 1.3051944299787779\n",
      "epoch : 0 , iter : 1600 , total_iter : 3691 , running_loss : 1.2556482533564202\n",
      "epoch : 0 , iter : 1700 , total_iter : 3691 , running_loss : 1.2103971225559396\n",
      "epoch : 0 , iter : 1800 , total_iter : 3691 , running_loss : 1.1677252433983105\n",
      "epoch : 0 , iter : 1900 , total_iter : 3691 , running_loss : 1.1284917941506067\n",
      "epoch : 0 , iter : 2000 , total_iter : 3691 , running_loss : 1.0914500785106305\n",
      "epoch : 0 , iter : 2100 , total_iter : 3691 , running_loss : 1.0581297669905472\n",
      "epoch : 0 , iter : 2200 , total_iter : 3691 , running_loss : 1.0253368505547125\n",
      "epoch : 0 , iter : 2300 , total_iter : 3691 , running_loss : 0.9953046943029079\n",
      "epoch : 0 , iter : 2400 , total_iter : 3691 , running_loss : 0.9666335318720077\n",
      "epoch : 0 , iter : 2500 , total_iter : 3691 , running_loss : 0.939779923742459\n",
      "epoch : 0 , iter : 2600 , total_iter : 3691 , running_loss : 0.914239697539316\n",
      "epoch : 0 , iter : 2700 , total_iter : 3691 , running_loss : 0.8909610218690175\n",
      "epoch : 0 , iter : 2800 , total_iter : 3691 , running_loss : 0.8691582330600656\n",
      "epoch : 0 , iter : 2900 , total_iter : 3691 , running_loss : 0.8482158612337904\n",
      "epoch : 0 , iter : 3000 , total_iter : 3691 , running_loss : 0.8277333047798339\n",
      "epoch : 0 , iter : 3100 , total_iter : 3691 , running_loss : 0.8083431484458217\n",
      "epoch : 0 , iter : 3200 , total_iter : 3691 , running_loss : 0.7903846402846624\n",
      "epoch : 0 , iter : 3300 , total_iter : 3691 , running_loss : 0.7737682086613928\n",
      "epoch : 0 , iter : 3400 , total_iter : 3691 , running_loss : 0.7576348764826816\n",
      "epoch : 0 , iter : 3500 , total_iter : 3691 , running_loss : 0.7427175856235027\n",
      "epoch : 0 , iter : 3600 , total_iter : 3691 , running_loss : 0.7277062669131564\n",
      "epoch : 1 , iter : 0 , total_iter : 3691 , running_loss : 0.13580116629600525\n",
      "epoch : 1 , iter : 100 , total_iter : 3691 , running_loss : 0.21067311813925751\n",
      "epoch : 1 , iter : 200 , total_iter : 3691 , running_loss : 0.20281466200428816\n",
      "epoch : 1 , iter : 300 , total_iter : 3691 , running_loss : 0.20021077567259735\n",
      "epoch : 1 , iter : 400 , total_iter : 3691 , running_loss : 0.19484418485675964\n",
      "epoch : 1 , iter : 500 , total_iter : 3691 , running_loss : 0.19048261953268697\n",
      "epoch : 1 , iter : 600 , total_iter : 3691 , running_loss : 0.18763177745205392\n",
      "epoch : 1 , iter : 700 , total_iter : 3691 , running_loss : 0.1842585755950544\n",
      "epoch : 1 , iter : 800 , total_iter : 3691 , running_loss : 0.18171484595380918\n",
      "epoch : 1 , iter : 900 , total_iter : 3691 , running_loss : 0.18228311134248013\n",
      "epoch : 1 , iter : 1000 , total_iter : 3691 , running_loss : 0.18068802573687429\n",
      "epoch : 1 , iter : 1100 , total_iter : 3691 , running_loss : 0.1759747851210275\n",
      "epoch : 1 , iter : 1200 , total_iter : 3691 , running_loss : 0.17348398467670076\n",
      "epoch : 1 , iter : 1300 , total_iter : 3691 , running_loss : 0.17233310920185624\n",
      "epoch : 1 , iter : 1400 , total_iter : 3691 , running_loss : 0.171211845268742\n",
      "epoch : 1 , iter : 1500 , total_iter : 3691 , running_loss : 0.1686267144556128\n",
      "epoch : 1 , iter : 1600 , total_iter : 3691 , running_loss : 0.16689470926908162\n",
      "epoch : 1 , iter : 1700 , total_iter : 3691 , running_loss : 0.1652029762301881\n",
      "epoch : 1 , iter : 1800 , total_iter : 3691 , running_loss : 0.16334660246612495\n",
      "epoch : 1 , iter : 1900 , total_iter : 3691 , running_loss : 0.16266197961672302\n",
      "epoch : 1 , iter : 2000 , total_iter : 3691 , running_loss : 0.16188241115983934\n",
      "epoch : 1 , iter : 2100 , total_iter : 3691 , running_loss : 0.1606589517671826\n",
      "epoch : 1 , iter : 2200 , total_iter : 3691 , running_loss : 0.15893928597815357\n",
      "epoch : 1 , iter : 2300 , total_iter : 3691 , running_loss : 0.1581004939743458\n",
      "epoch : 1 , iter : 2400 , total_iter : 3691 , running_loss : 0.1567979993400277\n",
      "epoch : 1 , iter : 2500 , total_iter : 3691 , running_loss : 0.15523653711806365\n",
      "epoch : 1 , iter : 2600 , total_iter : 3691 , running_loss : 0.15359930031184896\n",
      "epoch : 1 , iter : 2700 , total_iter : 3691 , running_loss : 0.15245591181474166\n",
      "epoch : 1 , iter : 2800 , total_iter : 3691 , running_loss : 0.1514682001728526\n",
      "epoch : 1 , iter : 2900 , total_iter : 3691 , running_loss : 0.15059490960768093\n",
      "epoch : 1 , iter : 3000 , total_iter : 3691 , running_loss : 0.14903688868796355\n",
      "epoch : 1 , iter : 3100 , total_iter : 3691 , running_loss : 0.1477720446179458\n",
      "epoch : 1 , iter : 3200 , total_iter : 3691 , running_loss : 0.14673645859680226\n",
      "epoch : 1 , iter : 3300 , total_iter : 3691 , running_loss : 0.14563346764716603\n",
      "epoch : 1 , iter : 3400 , total_iter : 3691 , running_loss : 0.14388138793356295\n",
      "epoch : 1 , iter : 3500 , total_iter : 3691 , running_loss : 0.14280592123569505\n",
      "epoch : 1 , iter : 3600 , total_iter : 3691 , running_loss : 0.14170800092490687\n",
      "epoch : 2 , iter : 0 , total_iter : 3691 , running_loss : 0.06531057506799698\n",
      "epoch : 2 , iter : 100 , total_iter : 3691 , running_loss : 0.08283873000136106\n",
      "epoch : 2 , iter : 200 , total_iter : 3691 , running_loss : 0.09407061482988187\n",
      "epoch : 2 , iter : 300 , total_iter : 3691 , running_loss : 0.09287928294798861\n",
      "epoch : 2 , iter : 400 , total_iter : 3691 , running_loss : 0.09212486233162762\n",
      "epoch : 2 , iter : 500 , total_iter : 3691 , running_loss : 0.09492219097079511\n",
      "epoch : 2 , iter : 600 , total_iter : 3691 , running_loss : 0.09518037480728302\n",
      "epoch : 2 , iter : 700 , total_iter : 3691 , running_loss : 0.09426337308363296\n",
      "epoch : 2 , iter : 800 , total_iter : 3691 , running_loss : 0.09344429186499967\n",
      "epoch : 2 , iter : 900 , total_iter : 3691 , running_loss : 0.09346850291845471\n",
      "epoch : 2 , iter : 1000 , total_iter : 3691 , running_loss : 0.09480785070867329\n",
      "epoch : 2 , iter : 1100 , total_iter : 3691 , running_loss : 0.09516869422444206\n",
      "epoch : 2 , iter : 1200 , total_iter : 3691 , running_loss : 0.09417158604245152\n",
      "epoch : 2 , iter : 1300 , total_iter : 3691 , running_loss : 0.09334004993373664\n",
      "epoch : 2 , iter : 1400 , total_iter : 3691 , running_loss : 0.09319408849908103\n",
      "epoch : 2 , iter : 1500 , total_iter : 3691 , running_loss : 0.0927627909584821\n",
      "epoch : 2 , iter : 1600 , total_iter : 3691 , running_loss : 0.09409014971695287\n",
      "epoch : 2 , iter : 1700 , total_iter : 3691 , running_loss : 0.09365388218243374\n",
      "epoch : 2 , iter : 1800 , total_iter : 3691 , running_loss : 0.09308762045816076\n",
      "epoch : 2 , iter : 1900 , total_iter : 3691 , running_loss : 0.09284723229433896\n",
      "epoch : 2 , iter : 2000 , total_iter : 3691 , running_loss : 0.0930109197485155\n",
      "epoch : 2 , iter : 2100 , total_iter : 3691 , running_loss : 0.09239290976876491\n",
      "epoch : 2 , iter : 2200 , total_iter : 3691 , running_loss : 0.09218944232362487\n",
      "epoch : 2 , iter : 2300 , total_iter : 3691 , running_loss : 0.0920397004744816\n",
      "epoch : 2 , iter : 2400 , total_iter : 3691 , running_loss : 0.09167504189159723\n",
      "epoch : 2 , iter : 2500 , total_iter : 3691 , running_loss : 0.09123816001923477\n",
      "epoch : 2 , iter : 2600 , total_iter : 3691 , running_loss : 0.09074260203381918\n",
      "epoch : 2 , iter : 2700 , total_iter : 3691 , running_loss : 0.09031836507736433\n",
      "epoch : 2 , iter : 2800 , total_iter : 3691 , running_loss : 0.09003258963813424\n",
      "epoch : 2 , iter : 2900 , total_iter : 3691 , running_loss : 0.08977703131049594\n",
      "epoch : 2 , iter : 3000 , total_iter : 3691 , running_loss : 0.08934415733365368\n",
      "epoch : 2 , iter : 3100 , total_iter : 3691 , running_loss : 0.08865382687616054\n",
      "epoch : 2 , iter : 3200 , total_iter : 3691 , running_loss : 0.08845793559387331\n",
      "epoch : 2 , iter : 3300 , total_iter : 3691 , running_loss : 0.0882242912363393\n",
      "epoch : 2 , iter : 3400 , total_iter : 3691 , running_loss : 0.08822629990982277\n",
      "epoch : 2 , iter : 3500 , total_iter : 3691 , running_loss : 0.08793466873530813\n",
      "epoch : 2 , iter : 3600 , total_iter : 3691 , running_loss : 0.08768016353644735\n",
      "epoch : 3 , iter : 0 , total_iter : 3691 , running_loss : 0.07288684695959091\n",
      "epoch : 3 , iter : 100 , total_iter : 3691 , running_loss : 0.0714601167837287\n",
      "epoch : 3 , iter : 200 , total_iter : 3691 , running_loss : 0.07303420235101708\n",
      "epoch : 3 , iter : 300 , total_iter : 3691 , running_loss : 0.07363081364536603\n",
      "epoch : 3 , iter : 400 , total_iter : 3691 , running_loss : 0.07351842261339883\n",
      "epoch : 3 , iter : 500 , total_iter : 3691 , running_loss : 0.07511558705483547\n",
      "epoch : 3 , iter : 600 , total_iter : 3691 , running_loss : 0.07657111861034856\n",
      "epoch : 3 , iter : 700 , total_iter : 3691 , running_loss : 0.07651401601715835\n",
      "epoch : 3 , iter : 800 , total_iter : 3691 , running_loss : 0.07576376295761297\n",
      "epoch : 3 , iter : 900 , total_iter : 3691 , running_loss : 0.07463251370895287\n",
      "epoch : 3 , iter : 1000 , total_iter : 3691 , running_loss : 0.07519808770729589\n",
      "epoch : 3 , iter : 1100 , total_iter : 3691 , running_loss : 0.07560946679776441\n",
      "epoch : 3 , iter : 1200 , total_iter : 3691 , running_loss : 0.0753916480766918\n",
      "epoch : 3 , iter : 1300 , total_iter : 3691 , running_loss : 0.07462901515037187\n",
      "epoch : 3 , iter : 1400 , total_iter : 3691 , running_loss : 0.0739397579520877\n",
      "epoch : 3 , iter : 1500 , total_iter : 3691 , running_loss : 0.07359107537970672\n",
      "epoch : 3 , iter : 1600 , total_iter : 3691 , running_loss : 0.0735887377642137\n",
      "epoch : 3 , iter : 1700 , total_iter : 3691 , running_loss : 0.07392984925430358\n",
      "epoch : 3 , iter : 1800 , total_iter : 3691 , running_loss : 0.07344430491539222\n",
      "epoch : 3 , iter : 1900 , total_iter : 3691 , running_loss : 0.07271731154369028\n",
      "epoch : 3 , iter : 2000 , total_iter : 3691 , running_loss : 0.07250116783837\n",
      "epoch : 3 , iter : 2100 , total_iter : 3691 , running_loss : 0.07209348848141882\n",
      "epoch : 3 , iter : 2200 , total_iter : 3691 , running_loss : 0.07157654519523343\n",
      "epoch : 3 , iter : 2300 , total_iter : 3691 , running_loss : 0.07186559774872014\n",
      "epoch : 3 , iter : 2400 , total_iter : 3691 , running_loss : 0.07173786313408385\n",
      "epoch : 3 , iter : 2500 , total_iter : 3691 , running_loss : 0.07173588123974628\n",
      "epoch : 3 , iter : 2600 , total_iter : 3691 , running_loss : 0.07162343439445908\n",
      "epoch : 3 , iter : 2700 , total_iter : 3691 , running_loss : 0.0712852861688454\n",
      "epoch : 3 , iter : 2800 , total_iter : 3691 , running_loss : 0.07090794691823953\n",
      "epoch : 3 , iter : 2900 , total_iter : 3691 , running_loss : 0.07072579036269341\n",
      "epoch : 3 , iter : 3000 , total_iter : 3691 , running_loss : 0.07090715576622415\n",
      "epoch : 3 , iter : 3100 , total_iter : 3691 , running_loss : 0.07078907332391805\n",
      "epoch : 3 , iter : 3200 , total_iter : 3691 , running_loss : 0.07053857194640904\n",
      "epoch : 3 , iter : 3300 , total_iter : 3691 , running_loss : 0.07061828197688497\n",
      "epoch : 3 , iter : 3400 , total_iter : 3691 , running_loss : 0.07066282363248656\n",
      "epoch : 3 , iter : 3500 , total_iter : 3691 , running_loss : 0.07069897614975434\n",
      "epoch : 3 , iter : 3600 , total_iter : 3691 , running_loss : 0.0706036737525173\n",
      "epoch : 4 , iter : 0 , total_iter : 3691 , running_loss : 0.040973518043756485\n",
      "epoch : 4 , iter : 100 , total_iter : 3691 , running_loss : 0.062167424837699034\n",
      "epoch : 4 , iter : 200 , total_iter : 3691 , running_loss : 0.06350641933950915\n",
      "epoch : 4 , iter : 300 , total_iter : 3691 , running_loss : 0.06256088848841497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 55\u001b[0m\n\u001b[1;32m     51\u001b[0m epoch_running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#tqdm_iterator = tqdm(data_loader[\"train\"], desc=f\"Epoch {epoch}\")\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     57\u001b[0m     imgs, masks \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     58\u001b[0m     imgs, masks \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(DEVICE), masks\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[0;32m~/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[11], line 65\u001b[0m, in \u001b[0;36mbuilding_dataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# image\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     67\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, dsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mIMAGE_SIZE,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mIMAGE_SIZE), interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_LINEAR)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#-- args\n",
    "import datetime\n",
    "\n",
    "EXEC_VER = 5 \n",
    "BATCH_SIZE = 8\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "#-- logger\n",
    "# Set up logging\n",
    "log_filename = datetime.datetime.now().strftime(f'./01.log/ver_{EXEC_VER}_%Y-%m-%d_%H-%M-%S.log')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "handler = logging.FileHandler(log_filename)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "#-- datasets \n",
    "train_dataset = building_dataset(img_dir=img_path, mask_dir=mask_path, phase=\"train\" )\n",
    "train_loader  = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataset = building_dataset(img_dir=img_path,mask_dir=mask_path, phase=\"val\" )\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "data_loader= {}\n",
    "data_loader[\"train\"] = train_loader\n",
    "data_loader[\"valid\"] = valid_loader\n",
    "\n",
    "#-- model \n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"resnet152\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=16,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#-- loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#-- optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# run\n",
    "epochs = 999\n",
    "iteration = 0\n",
    "total_loss = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    iteration = 0\n",
    "    epoch_running_loss = 0 \n",
    "    \n",
    "    #tqdm_iterator = tqdm(data_loader[\"train\"], desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    for index, data in enumerate(data_loader[\"train\"]):\n",
    "        \n",
    "        imgs, masks = data\n",
    "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "        \n",
    "        # opt\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # runs\n",
    "        outputs = model(imgs)\n",
    "        \n",
    "        # loss\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # stat\n",
    "        epoch_running_loss += loss.item()\n",
    "\n",
    "        # log\n",
    "        logger.info(f\"epoch : {epoch} iter : {index} loss: {loss:.8f}\")\n",
    "        log = {'loss': f'{loss / 10:.8f}' }\n",
    "        #wandb.log(log)\n",
    "\n",
    "        log_iter = 100\n",
    "        \n",
    "        if (index % log_iter) == 0:    # print every 2000 mini-batches\n",
    "            print(f\"epoch : {epoch} , iter : {index} , total_iter : {len(data_loader['train'])} , running_loss : {epoch_running_loss / (index +1)}\")\n",
    "        \n",
    "    \n",
    "    #-- save \n",
    "    save_path = f\"./02.ckpts/model_ver_{EXEC_VER}_{epoch + 1}.pt\"\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "8.tmp.copied",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
