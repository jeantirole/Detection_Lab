{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = \"./swint_upernet_imp_sep_model.pth\"\n",
    "a = torch.load(model_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'iteration', 'state_dict', 'optimizer', 'scheduler', 'loss_pretrain'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "swin_uper_keys = a[\"state_dict\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder.patch_embed.proj.weight',\n",
       " 'encoder.patch_embed.proj.bias',\n",
       " 'encoder.patch_embed.norm.weight',\n",
       " 'encoder.patch_embed.norm.bias',\n",
       " 'encoder.layers.0.blocks.0.norm1.weight',\n",
       " 'encoder.layers.0.blocks.0.norm1.bias',\n",
       " 'encoder.layers.0.blocks.0.attn.relative_position_bias_table',\n",
       " 'encoder.layers.0.blocks.0.attn.relative_position_index',\n",
       " 'encoder.layers.0.blocks.0.attn.qkv.weight',\n",
       " 'encoder.layers.0.blocks.0.attn.qkv.bias',\n",
       " 'encoder.layers.0.blocks.0.attn.proj.weight',\n",
       " 'encoder.layers.0.blocks.0.attn.proj.bias',\n",
       " 'encoder.layers.0.blocks.0.norm2.weight',\n",
       " 'encoder.layers.0.blocks.0.norm2.bias',\n",
       " 'encoder.layers.0.blocks.0.mlp.fc1.weight',\n",
       " 'encoder.layers.0.blocks.0.mlp.fc1.bias',\n",
       " 'encoder.layers.0.blocks.0.mlp.fc2.weight',\n",
       " 'encoder.layers.0.blocks.0.mlp.fc2.bias',\n",
       " 'encoder.layers.0.blocks.1.norm1.weight',\n",
       " 'encoder.layers.0.blocks.1.norm1.bias',\n",
       " 'encoder.layers.0.blocks.1.attn.relative_position_bias_table',\n",
       " 'encoder.layers.0.blocks.1.attn.relative_position_index',\n",
       " 'encoder.layers.0.blocks.1.attn.qkv.weight',\n",
       " 'encoder.layers.0.blocks.1.attn.qkv.bias',\n",
       " 'encoder.layers.0.blocks.1.attn.proj.weight',\n",
       " 'encoder.layers.0.blocks.1.attn.proj.bias',\n",
       " 'encoder.layers.0.blocks.1.norm2.weight',\n",
       " 'encoder.layers.0.blocks.1.norm2.bias',\n",
       " 'encoder.layers.0.blocks.1.mlp.fc1.weight',\n",
       " 'encoder.layers.0.blocks.1.mlp.fc1.bias',\n",
       " 'encoder.layers.0.blocks.1.mlp.fc2.weight',\n",
       " 'encoder.layers.0.blocks.1.mlp.fc2.bias',\n",
       " 'encoder.layers.0.downsample.reduction.weight',\n",
       " 'encoder.layers.0.downsample.norm.weight',\n",
       " 'encoder.layers.0.downsample.norm.bias',\n",
       " 'encoder.layers.1.blocks.0.norm1.weight',\n",
       " 'encoder.layers.1.blocks.0.norm1.bias',\n",
       " 'encoder.layers.1.blocks.0.attn.relative_position_bias_table',\n",
       " 'encoder.layers.1.blocks.0.attn.relative_position_index',\n",
       " 'encoder.layers.1.blocks.0.attn.qkv.weight',\n",
       " 'encoder.layers.1.blocks.0.attn.qkv.bias',\n",
       " 'encoder.layers.1.blocks.0.attn.proj.weight',\n",
       " 'encoder.layers.1.blocks.0.attn.proj.bias',\n",
       " 'encoder.layers.1.blocks.0.norm2.weight',\n",
       " 'encoder.layers.1.blocks.0.norm2.bias',\n",
       " 'encoder.layers.1.blocks.0.mlp.fc1.weight',\n",
       " 'encoder.layers.1.blocks.0.mlp.fc1.bias',\n",
       " 'encoder.layers.1.blocks.0.mlp.fc2.weight',\n",
       " 'encoder.layers.1.blocks.0.mlp.fc2.bias',\n",
       " 'encoder.layers.1.blocks.1.norm1.weight',\n",
       " 'encoder.layers.1.blocks.1.norm1.bias',\n",
       " 'encoder.layers.1.blocks.1.attn.relative_position_bias_table',\n",
       " 'encoder.layers.1.blocks.1.attn.relative_position_index',\n",
       " 'encoder.layers.1.blocks.1.attn.qkv.weight',\n",
       " 'encoder.layers.1.blocks.1.attn.qkv.bias',\n",
       " 'encoder.layers.1.blocks.1.attn.proj.weight',\n",
       " 'encoder.layers.1.blocks.1.attn.proj.bias',\n",
       " 'encoder.layers.1.blocks.1.norm2.weight',\n",
       " 'encoder.layers.1.blocks.1.norm2.bias',\n",
       " 'encoder.layers.1.blocks.1.mlp.fc1.weight',\n",
       " 'encoder.layers.1.blocks.1.mlp.fc1.bias',\n",
       " 'encoder.layers.1.blocks.1.mlp.fc2.weight',\n",
       " 'encoder.layers.1.blocks.1.mlp.fc2.bias',\n",
       " 'encoder.layers.1.downsample.reduction.weight',\n",
       " 'encoder.layers.1.downsample.norm.weight',\n",
       " 'encoder.layers.1.downsample.norm.bias',\n",
       " 'encoder.layers.2.blocks.0.norm1.weight',\n",
       " 'encoder.layers.2.blocks.0.norm1.bias',\n",
       " 'encoder.layers.2.blocks.0.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.0.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.0.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.0.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.0.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.0.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.0.norm2.weight',\n",
       " 'encoder.layers.2.blocks.0.norm2.bias',\n",
       " 'encoder.layers.2.blocks.0.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.0.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.0.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.0.mlp.fc2.bias',\n",
       " 'encoder.layers.2.blocks.1.norm1.weight',\n",
       " 'encoder.layers.2.blocks.1.norm1.bias',\n",
       " 'encoder.layers.2.blocks.1.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.1.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.1.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.1.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.1.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.1.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.1.norm2.weight',\n",
       " 'encoder.layers.2.blocks.1.norm2.bias',\n",
       " 'encoder.layers.2.blocks.1.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.1.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.1.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.1.mlp.fc2.bias',\n",
       " 'encoder.layers.2.blocks.2.norm1.weight',\n",
       " 'encoder.layers.2.blocks.2.norm1.bias',\n",
       " 'encoder.layers.2.blocks.2.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.2.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.2.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.2.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.2.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.2.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.2.norm2.weight',\n",
       " 'encoder.layers.2.blocks.2.norm2.bias',\n",
       " 'encoder.layers.2.blocks.2.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.2.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.2.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.2.mlp.fc2.bias',\n",
       " 'encoder.layers.2.blocks.3.norm1.weight',\n",
       " 'encoder.layers.2.blocks.3.norm1.bias',\n",
       " 'encoder.layers.2.blocks.3.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.3.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.3.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.3.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.3.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.3.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.3.norm2.weight',\n",
       " 'encoder.layers.2.blocks.3.norm2.bias',\n",
       " 'encoder.layers.2.blocks.3.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.3.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.3.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.3.mlp.fc2.bias',\n",
       " 'encoder.layers.2.blocks.4.norm1.weight',\n",
       " 'encoder.layers.2.blocks.4.norm1.bias',\n",
       " 'encoder.layers.2.blocks.4.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.4.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.4.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.4.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.4.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.4.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.4.norm2.weight',\n",
       " 'encoder.layers.2.blocks.4.norm2.bias',\n",
       " 'encoder.layers.2.blocks.4.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.4.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.4.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.4.mlp.fc2.bias',\n",
       " 'encoder.layers.2.blocks.5.norm1.weight',\n",
       " 'encoder.layers.2.blocks.5.norm1.bias',\n",
       " 'encoder.layers.2.blocks.5.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.5.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.5.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.5.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.5.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.5.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.5.norm2.weight',\n",
       " 'encoder.layers.2.blocks.5.norm2.bias',\n",
       " 'encoder.layers.2.blocks.5.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.5.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.5.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.5.mlp.fc2.bias',\n",
       " 'encoder.layers.2.downsample.reduction.weight',\n",
       " 'encoder.layers.2.downsample.norm.weight',\n",
       " 'encoder.layers.2.downsample.norm.bias',\n",
       " 'encoder.layers.3.blocks.0.norm1.weight',\n",
       " 'encoder.layers.3.blocks.0.norm1.bias',\n",
       " 'encoder.layers.3.blocks.0.attn.relative_position_bias_table',\n",
       " 'encoder.layers.3.blocks.0.attn.relative_position_index',\n",
       " 'encoder.layers.3.blocks.0.attn.qkv.weight',\n",
       " 'encoder.layers.3.blocks.0.attn.qkv.bias',\n",
       " 'encoder.layers.3.blocks.0.attn.proj.weight',\n",
       " 'encoder.layers.3.blocks.0.attn.proj.bias',\n",
       " 'encoder.layers.3.blocks.0.norm2.weight',\n",
       " 'encoder.layers.3.blocks.0.norm2.bias',\n",
       " 'encoder.layers.3.blocks.0.mlp.fc1.weight',\n",
       " 'encoder.layers.3.blocks.0.mlp.fc1.bias',\n",
       " 'encoder.layers.3.blocks.0.mlp.fc2.weight',\n",
       " 'encoder.layers.3.blocks.0.mlp.fc2.bias',\n",
       " 'encoder.layers.3.blocks.1.norm1.weight',\n",
       " 'encoder.layers.3.blocks.1.norm1.bias',\n",
       " 'encoder.layers.3.blocks.1.attn.relative_position_bias_table',\n",
       " 'encoder.layers.3.blocks.1.attn.relative_position_index',\n",
       " 'encoder.layers.3.blocks.1.attn.qkv.weight',\n",
       " 'encoder.layers.3.blocks.1.attn.qkv.bias',\n",
       " 'encoder.layers.3.blocks.1.attn.proj.weight',\n",
       " 'encoder.layers.3.blocks.1.attn.proj.bias',\n",
       " 'encoder.layers.3.blocks.1.norm2.weight',\n",
       " 'encoder.layers.3.blocks.1.norm2.bias',\n",
       " 'encoder.layers.3.blocks.1.mlp.fc1.weight',\n",
       " 'encoder.layers.3.blocks.1.mlp.fc1.bias',\n",
       " 'encoder.layers.3.blocks.1.mlp.fc2.weight',\n",
       " 'encoder.layers.3.blocks.1.mlp.fc2.bias',\n",
       " 'encoder.norm0.weight',\n",
       " 'encoder.norm0.bias',\n",
       " 'encoder.norm1.weight',\n",
       " 'encoder.norm1.bias',\n",
       " 'encoder.norm2.weight',\n",
       " 'encoder.norm2.bias',\n",
       " 'encoder.norm3.weight',\n",
       " 'encoder.norm3.bias',\n",
       " 'decoder.psp_modules.0.1.conv.weight',\n",
       " 'decoder.psp_modules.0.1.bn.weight',\n",
       " 'decoder.psp_modules.0.1.bn.bias',\n",
       " 'decoder.psp_modules.0.1.bn.running_mean',\n",
       " 'decoder.psp_modules.0.1.bn.running_var',\n",
       " 'decoder.psp_modules.0.1.bn.num_batches_tracked',\n",
       " 'decoder.psp_modules.1.1.conv.weight',\n",
       " 'decoder.psp_modules.1.1.bn.weight',\n",
       " 'decoder.psp_modules.1.1.bn.bias',\n",
       " 'decoder.psp_modules.1.1.bn.running_mean',\n",
       " 'decoder.psp_modules.1.1.bn.running_var',\n",
       " 'decoder.psp_modules.1.1.bn.num_batches_tracked',\n",
       " 'decoder.psp_modules.2.1.conv.weight',\n",
       " 'decoder.psp_modules.2.1.bn.weight',\n",
       " 'decoder.psp_modules.2.1.bn.bias',\n",
       " 'decoder.psp_modules.2.1.bn.running_mean',\n",
       " 'decoder.psp_modules.2.1.bn.running_var',\n",
       " 'decoder.psp_modules.2.1.bn.num_batches_tracked',\n",
       " 'decoder.psp_modules.3.1.conv.weight',\n",
       " 'decoder.psp_modules.3.1.bn.weight',\n",
       " 'decoder.psp_modules.3.1.bn.bias',\n",
       " 'decoder.psp_modules.3.1.bn.running_mean',\n",
       " 'decoder.psp_modules.3.1.bn.running_var',\n",
       " 'decoder.psp_modules.3.1.bn.num_batches_tracked',\n",
       " 'decoder.bottleneck.conv.weight',\n",
       " 'decoder.bottleneck.bn.weight',\n",
       " 'decoder.bottleneck.bn.bias',\n",
       " 'decoder.bottleneck.bn.running_mean',\n",
       " 'decoder.bottleneck.bn.running_var',\n",
       " 'decoder.bottleneck.bn.num_batches_tracked',\n",
       " 'decoder.lateral_convs.0.conv.weight',\n",
       " 'decoder.lateral_convs.0.bn.weight',\n",
       " 'decoder.lateral_convs.0.bn.bias',\n",
       " 'decoder.lateral_convs.0.bn.running_mean',\n",
       " 'decoder.lateral_convs.0.bn.running_var',\n",
       " 'decoder.lateral_convs.0.bn.num_batches_tracked',\n",
       " 'decoder.lateral_convs.1.conv.weight',\n",
       " 'decoder.lateral_convs.1.bn.weight',\n",
       " 'decoder.lateral_convs.1.bn.bias',\n",
       " 'decoder.lateral_convs.1.bn.running_mean',\n",
       " 'decoder.lateral_convs.1.bn.running_var',\n",
       " 'decoder.lateral_convs.1.bn.num_batches_tracked',\n",
       " 'decoder.lateral_convs.2.conv.weight',\n",
       " 'decoder.lateral_convs.2.bn.weight',\n",
       " 'decoder.lateral_convs.2.bn.bias',\n",
       " 'decoder.lateral_convs.2.bn.running_mean',\n",
       " 'decoder.lateral_convs.2.bn.running_var',\n",
       " 'decoder.lateral_convs.2.bn.num_batches_tracked',\n",
       " 'decoder.fpn_convs.0.conv.weight',\n",
       " 'decoder.fpn_convs.0.bn.weight',\n",
       " 'decoder.fpn_convs.0.bn.bias',\n",
       " 'decoder.fpn_convs.0.bn.running_mean',\n",
       " 'decoder.fpn_convs.0.bn.running_var',\n",
       " 'decoder.fpn_convs.0.bn.num_batches_tracked',\n",
       " 'decoder.fpn_convs.1.conv.weight',\n",
       " 'decoder.fpn_convs.1.bn.weight',\n",
       " 'decoder.fpn_convs.1.bn.bias',\n",
       " 'decoder.fpn_convs.1.bn.running_mean',\n",
       " 'decoder.fpn_convs.1.bn.running_var',\n",
       " 'decoder.fpn_convs.1.bn.num_batches_tracked',\n",
       " 'decoder.fpn_convs.2.conv.weight',\n",
       " 'decoder.fpn_convs.2.bn.weight',\n",
       " 'decoder.fpn_convs.2.bn.bias',\n",
       " 'decoder.fpn_convs.2.bn.running_mean',\n",
       " 'decoder.fpn_convs.2.bn.running_var',\n",
       " 'decoder.fpn_convs.2.bn.num_batches_tracked',\n",
       " 'decoder.fpn_bottleneck.conv.weight',\n",
       " 'decoder.fpn_bottleneck.bn.weight',\n",
       " 'decoder.fpn_bottleneck.bn.bias',\n",
       " 'decoder.fpn_bottleneck.bn.running_mean',\n",
       " 'decoder.fpn_bottleneck.bn.running_var',\n",
       " 'decoder.fpn_bottleneck.bn.num_batches_tracked',\n",
       " 'semseghead_1.1.weight',\n",
       " 'semseghead_1.1.bias',\n",
       " 'semseghead_2.1.weight',\n",
       " 'semseghead_2.1.bias',\n",
       " 'semseghead_3.1.weight',\n",
       " 'semseghead_3.1.bias']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in swin_uper_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd/eric/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model_swin = swin.swin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.randn(4,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ = model_swin(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768, 7, 7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 192, 384, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_swin.out_channels[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import upper_net_mmseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_upernet = upper_net_mmseg.UPerHead(\n",
    "    in_channels = model_swin.out_channels[1:],\n",
    "    channels = model_swin.out_channels[2],\n",
    "    in_index= (0,1,2,3),\n",
    "    dropout_ratio=0.1,\n",
    "    norm_cfg= dict(type='SyncBN', requires_grad=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UPerHead(\n",
       "  input_transform=multiple_select, ignore_index=255, align_corners=False\n",
       "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "  (psp_modules): PPM(\n",
       "    (0): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=1)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=2)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=3)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=6)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): ConvModule(\n",
       "    (conv): Conv2d(1536, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate): ReLU(inplace=True)\n",
       "  )\n",
       "  (lateral_convs): ModuleList(\n",
       "    (0): ConvModule(\n",
       "      (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "    (1): ConvModule(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "    (2): ConvModule(\n",
       "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fpn_convs): ModuleList(\n",
       "    (0): ConvModule(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "    (1): ConvModule(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "    (2): ConvModule(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fpn_bottleneck): ConvModule(\n",
       "    (conv): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate): ReLU(inplace=True)\n",
       "  )\n",
       ")\n",
       "init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_upernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     print('################# Using UNet for Pretraining! ######################')\n",
    "\n",
    "# elif args.decoder == 'upernet':\n",
    "\n",
    "#     self.decoder = UPerHead(\n",
    "#         in_channels = self.encoder.out_channels[1:],\n",
    "#         channels = self.encoder.out_channels[2],\n",
    "#         in_index = (0, 1, 2, 3),\n",
    "#         dropout_ratio = 0.1,\n",
    "#         norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "class SamRS(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                model1=None,\n",
    "                model2=None, \n",
    "                decoder_use_batchnorm: bool = True,\n",
    "                decoder_channels  = (512, 256, 128, 64), #(256, 128, 64, 32, 16),\n",
    "                decoder_attention_type = None,\n",
    "                classes1: int = 18,\n",
    "                classes2: int = 20,\n",
    "                classes3: int = 37,\n",
    "                activation: str = None,\n",
    "                aux_params: dict = None):\n",
    "        \n",
    "        super(SamRS,self).__init__()\n",
    "        \n",
    "        self.encoder = model1 \n",
    "        self.decoder = model2\n",
    "        self.semseghead_1 = nn.Sequential(\n",
    "                nn.Dropout2d(0.1),\n",
    "                nn.Conv2d(self.encoder.out_channels[2], classes1, kernel_size=1)\n",
    "            )\n",
    "\n",
    "        self.semseghead_2 = nn.Sequential(\n",
    "                nn.Dropout2d(0.1),\n",
    "                nn.Conv2d(self.encoder.out_channels[2], classes2, kernel_size=1)\n",
    "            )\n",
    "\n",
    "        self.semseghead_3 = nn.Sequential(\n",
    "                nn.Dropout2d(0.1),\n",
    "                nn.Conv2d(self.encoder.out_channels[2], classes3, kernel_size=1)\n",
    "            )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(*features)\n",
    "        output_1 = self.semseghead_1(output)\n",
    "        output_2 = self.semseghead_2(output)\n",
    "        output_3 = self.semseghead_3(output)\n",
    "        \n",
    "        return output_3\n",
    "\n",
    "#---------------------------------------    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "samrs_model = SamRS(model1=model_swin, model2=model_upernet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder.patch_embed.proj.weight',\n",
       " 'encoder.patch_embed.proj.bias',\n",
       " 'encoder.patch_embed.norm.weight',\n",
       " 'encoder.patch_embed.norm.bias',\n",
       " 'encoder.layers.0.blocks.0.norm1.weight',\n",
       " 'encoder.layers.0.blocks.0.norm1.bias',\n",
       " 'encoder.layers.0.blocks.0.attn.relative_position_bias_table',\n",
       " 'encoder.layers.0.blocks.0.attn.relative_position_index',\n",
       " 'encoder.layers.0.blocks.0.attn.qkv.weight',\n",
       " 'encoder.layers.0.blocks.0.attn.qkv.bias',\n",
       " 'encoder.layers.0.blocks.0.attn.proj.weight',\n",
       " 'encoder.layers.0.blocks.0.attn.proj.bias',\n",
       " 'encoder.layers.0.blocks.0.norm2.weight',\n",
       " 'encoder.layers.0.blocks.0.norm2.bias',\n",
       " 'encoder.layers.0.blocks.0.mlp.fc1.weight',\n",
       " 'encoder.layers.0.blocks.0.mlp.fc1.bias',\n",
       " 'encoder.layers.0.blocks.0.mlp.fc2.weight',\n",
       " 'encoder.layers.0.blocks.0.mlp.fc2.bias',\n",
       " 'encoder.layers.0.blocks.1.norm1.weight',\n",
       " 'encoder.layers.0.blocks.1.norm1.bias',\n",
       " 'encoder.layers.0.blocks.1.attn.relative_position_bias_table',\n",
       " 'encoder.layers.0.blocks.1.attn.relative_position_index',\n",
       " 'encoder.layers.0.blocks.1.attn.qkv.weight',\n",
       " 'encoder.layers.0.blocks.1.attn.qkv.bias',\n",
       " 'encoder.layers.0.blocks.1.attn.proj.weight',\n",
       " 'encoder.layers.0.blocks.1.attn.proj.bias',\n",
       " 'encoder.layers.0.blocks.1.norm2.weight',\n",
       " 'encoder.layers.0.blocks.1.norm2.bias',\n",
       " 'encoder.layers.0.blocks.1.mlp.fc1.weight',\n",
       " 'encoder.layers.0.blocks.1.mlp.fc1.bias',\n",
       " 'encoder.layers.0.blocks.1.mlp.fc2.weight',\n",
       " 'encoder.layers.0.blocks.1.mlp.fc2.bias',\n",
       " 'encoder.layers.0.downsample.reduction.weight',\n",
       " 'encoder.layers.0.downsample.norm.weight',\n",
       " 'encoder.layers.0.downsample.norm.bias',\n",
       " 'encoder.layers.1.blocks.0.norm1.weight',\n",
       " 'encoder.layers.1.blocks.0.norm1.bias',\n",
       " 'encoder.layers.1.blocks.0.attn.relative_position_bias_table',\n",
       " 'encoder.layers.1.blocks.0.attn.relative_position_index',\n",
       " 'encoder.layers.1.blocks.0.attn.qkv.weight',\n",
       " 'encoder.layers.1.blocks.0.attn.qkv.bias',\n",
       " 'encoder.layers.1.blocks.0.attn.proj.weight',\n",
       " 'encoder.layers.1.blocks.0.attn.proj.bias',\n",
       " 'encoder.layers.1.blocks.0.norm2.weight',\n",
       " 'encoder.layers.1.blocks.0.norm2.bias',\n",
       " 'encoder.layers.1.blocks.0.mlp.fc1.weight',\n",
       " 'encoder.layers.1.blocks.0.mlp.fc1.bias',\n",
       " 'encoder.layers.1.blocks.0.mlp.fc2.weight',\n",
       " 'encoder.layers.1.blocks.0.mlp.fc2.bias',\n",
       " 'encoder.layers.1.blocks.1.norm1.weight',\n",
       " 'encoder.layers.1.blocks.1.norm1.bias',\n",
       " 'encoder.layers.1.blocks.1.attn.relative_position_bias_table',\n",
       " 'encoder.layers.1.blocks.1.attn.relative_position_index',\n",
       " 'encoder.layers.1.blocks.1.attn.qkv.weight',\n",
       " 'encoder.layers.1.blocks.1.attn.qkv.bias',\n",
       " 'encoder.layers.1.blocks.1.attn.proj.weight',\n",
       " 'encoder.layers.1.blocks.1.attn.proj.bias',\n",
       " 'encoder.layers.1.blocks.1.norm2.weight',\n",
       " 'encoder.layers.1.blocks.1.norm2.bias',\n",
       " 'encoder.layers.1.blocks.1.mlp.fc1.weight',\n",
       " 'encoder.layers.1.blocks.1.mlp.fc1.bias',\n",
       " 'encoder.layers.1.blocks.1.mlp.fc2.weight',\n",
       " 'encoder.layers.1.blocks.1.mlp.fc2.bias',\n",
       " 'encoder.layers.1.downsample.reduction.weight',\n",
       " 'encoder.layers.1.downsample.norm.weight',\n",
       " 'encoder.layers.1.downsample.norm.bias',\n",
       " 'encoder.layers.2.blocks.0.norm1.weight',\n",
       " 'encoder.layers.2.blocks.0.norm1.bias',\n",
       " 'encoder.layers.2.blocks.0.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.0.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.0.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.0.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.0.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.0.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.0.norm2.weight',\n",
       " 'encoder.layers.2.blocks.0.norm2.bias',\n",
       " 'encoder.layers.2.blocks.0.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.0.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.0.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.0.mlp.fc2.bias',\n",
       " 'encoder.layers.2.blocks.1.norm1.weight',\n",
       " 'encoder.layers.2.blocks.1.norm1.bias',\n",
       " 'encoder.layers.2.blocks.1.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.1.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.1.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.1.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.1.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.1.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.1.norm2.weight',\n",
       " 'encoder.layers.2.blocks.1.norm2.bias',\n",
       " 'encoder.layers.2.blocks.1.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.1.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.1.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.1.mlp.fc2.bias',\n",
       " 'encoder.layers.2.blocks.2.norm1.weight',\n",
       " 'encoder.layers.2.blocks.2.norm1.bias',\n",
       " 'encoder.layers.2.blocks.2.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.2.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.2.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.2.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.2.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.2.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.2.norm2.weight',\n",
       " 'encoder.layers.2.blocks.2.norm2.bias',\n",
       " 'encoder.layers.2.blocks.2.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.2.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.2.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.2.mlp.fc2.bias',\n",
       " 'encoder.layers.2.blocks.3.norm1.weight',\n",
       " 'encoder.layers.2.blocks.3.norm1.bias',\n",
       " 'encoder.layers.2.blocks.3.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.3.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.3.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.3.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.3.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.3.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.3.norm2.weight',\n",
       " 'encoder.layers.2.blocks.3.norm2.bias',\n",
       " 'encoder.layers.2.blocks.3.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.3.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.3.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.3.mlp.fc2.bias',\n",
       " 'encoder.layers.2.blocks.4.norm1.weight',\n",
       " 'encoder.layers.2.blocks.4.norm1.bias',\n",
       " 'encoder.layers.2.blocks.4.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.4.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.4.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.4.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.4.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.4.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.4.norm2.weight',\n",
       " 'encoder.layers.2.blocks.4.norm2.bias',\n",
       " 'encoder.layers.2.blocks.4.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.4.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.4.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.4.mlp.fc2.bias',\n",
       " 'encoder.layers.2.blocks.5.norm1.weight',\n",
       " 'encoder.layers.2.blocks.5.norm1.bias',\n",
       " 'encoder.layers.2.blocks.5.attn.relative_position_bias_table',\n",
       " 'encoder.layers.2.blocks.5.attn.relative_position_index',\n",
       " 'encoder.layers.2.blocks.5.attn.qkv.weight',\n",
       " 'encoder.layers.2.blocks.5.attn.qkv.bias',\n",
       " 'encoder.layers.2.blocks.5.attn.proj.weight',\n",
       " 'encoder.layers.2.blocks.5.attn.proj.bias',\n",
       " 'encoder.layers.2.blocks.5.norm2.weight',\n",
       " 'encoder.layers.2.blocks.5.norm2.bias',\n",
       " 'encoder.layers.2.blocks.5.mlp.fc1.weight',\n",
       " 'encoder.layers.2.blocks.5.mlp.fc1.bias',\n",
       " 'encoder.layers.2.blocks.5.mlp.fc2.weight',\n",
       " 'encoder.layers.2.blocks.5.mlp.fc2.bias',\n",
       " 'encoder.layers.2.downsample.reduction.weight',\n",
       " 'encoder.layers.2.downsample.norm.weight',\n",
       " 'encoder.layers.2.downsample.norm.bias',\n",
       " 'encoder.layers.3.blocks.0.norm1.weight',\n",
       " 'encoder.layers.3.blocks.0.norm1.bias',\n",
       " 'encoder.layers.3.blocks.0.attn.relative_position_bias_table',\n",
       " 'encoder.layers.3.blocks.0.attn.relative_position_index',\n",
       " 'encoder.layers.3.blocks.0.attn.qkv.weight',\n",
       " 'encoder.layers.3.blocks.0.attn.qkv.bias',\n",
       " 'encoder.layers.3.blocks.0.attn.proj.weight',\n",
       " 'encoder.layers.3.blocks.0.attn.proj.bias',\n",
       " 'encoder.layers.3.blocks.0.norm2.weight',\n",
       " 'encoder.layers.3.blocks.0.norm2.bias',\n",
       " 'encoder.layers.3.blocks.0.mlp.fc1.weight',\n",
       " 'encoder.layers.3.blocks.0.mlp.fc1.bias',\n",
       " 'encoder.layers.3.blocks.0.mlp.fc2.weight',\n",
       " 'encoder.layers.3.blocks.0.mlp.fc2.bias',\n",
       " 'encoder.layers.3.blocks.1.norm1.weight',\n",
       " 'encoder.layers.3.blocks.1.norm1.bias',\n",
       " 'encoder.layers.3.blocks.1.attn.relative_position_bias_table',\n",
       " 'encoder.layers.3.blocks.1.attn.relative_position_index',\n",
       " 'encoder.layers.3.blocks.1.attn.qkv.weight',\n",
       " 'encoder.layers.3.blocks.1.attn.qkv.bias',\n",
       " 'encoder.layers.3.blocks.1.attn.proj.weight',\n",
       " 'encoder.layers.3.blocks.1.attn.proj.bias',\n",
       " 'encoder.layers.3.blocks.1.norm2.weight',\n",
       " 'encoder.layers.3.blocks.1.norm2.bias',\n",
       " 'encoder.layers.3.blocks.1.mlp.fc1.weight',\n",
       " 'encoder.layers.3.blocks.1.mlp.fc1.bias',\n",
       " 'encoder.layers.3.blocks.1.mlp.fc2.weight',\n",
       " 'encoder.layers.3.blocks.1.mlp.fc2.bias',\n",
       " 'encoder.norm0.weight',\n",
       " 'encoder.norm0.bias',\n",
       " 'encoder.norm1.weight',\n",
       " 'encoder.norm1.bias',\n",
       " 'encoder.norm2.weight',\n",
       " 'encoder.norm2.bias',\n",
       " 'encoder.norm3.weight',\n",
       " 'encoder.norm3.bias',\n",
       " 'decoder.psp_modules.0.1.conv.weight',\n",
       " 'decoder.psp_modules.0.1.bn.weight',\n",
       " 'decoder.psp_modules.0.1.bn.bias',\n",
       " 'decoder.psp_modules.0.1.bn.running_mean',\n",
       " 'decoder.psp_modules.0.1.bn.running_var',\n",
       " 'decoder.psp_modules.0.1.bn.num_batches_tracked',\n",
       " 'decoder.psp_modules.1.1.conv.weight',\n",
       " 'decoder.psp_modules.1.1.bn.weight',\n",
       " 'decoder.psp_modules.1.1.bn.bias',\n",
       " 'decoder.psp_modules.1.1.bn.running_mean',\n",
       " 'decoder.psp_modules.1.1.bn.running_var',\n",
       " 'decoder.psp_modules.1.1.bn.num_batches_tracked',\n",
       " 'decoder.psp_modules.2.1.conv.weight',\n",
       " 'decoder.psp_modules.2.1.bn.weight',\n",
       " 'decoder.psp_modules.2.1.bn.bias',\n",
       " 'decoder.psp_modules.2.1.bn.running_mean',\n",
       " 'decoder.psp_modules.2.1.bn.running_var',\n",
       " 'decoder.psp_modules.2.1.bn.num_batches_tracked',\n",
       " 'decoder.psp_modules.3.1.conv.weight',\n",
       " 'decoder.psp_modules.3.1.bn.weight',\n",
       " 'decoder.psp_modules.3.1.bn.bias',\n",
       " 'decoder.psp_modules.3.1.bn.running_mean',\n",
       " 'decoder.psp_modules.3.1.bn.running_var',\n",
       " 'decoder.psp_modules.3.1.bn.num_batches_tracked',\n",
       " 'decoder.bottleneck.conv.weight',\n",
       " 'decoder.bottleneck.bn.weight',\n",
       " 'decoder.bottleneck.bn.bias',\n",
       " 'decoder.bottleneck.bn.running_mean',\n",
       " 'decoder.bottleneck.bn.running_var',\n",
       " 'decoder.bottleneck.bn.num_batches_tracked',\n",
       " 'decoder.lateral_convs.0.conv.weight',\n",
       " 'decoder.lateral_convs.0.bn.weight',\n",
       " 'decoder.lateral_convs.0.bn.bias',\n",
       " 'decoder.lateral_convs.0.bn.running_mean',\n",
       " 'decoder.lateral_convs.0.bn.running_var',\n",
       " 'decoder.lateral_convs.0.bn.num_batches_tracked',\n",
       " 'decoder.lateral_convs.1.conv.weight',\n",
       " 'decoder.lateral_convs.1.bn.weight',\n",
       " 'decoder.lateral_convs.1.bn.bias',\n",
       " 'decoder.lateral_convs.1.bn.running_mean',\n",
       " 'decoder.lateral_convs.1.bn.running_var',\n",
       " 'decoder.lateral_convs.1.bn.num_batches_tracked',\n",
       " 'decoder.lateral_convs.2.conv.weight',\n",
       " 'decoder.lateral_convs.2.bn.weight',\n",
       " 'decoder.lateral_convs.2.bn.bias',\n",
       " 'decoder.lateral_convs.2.bn.running_mean',\n",
       " 'decoder.lateral_convs.2.bn.running_var',\n",
       " 'decoder.lateral_convs.2.bn.num_batches_tracked',\n",
       " 'decoder.fpn_convs.0.conv.weight',\n",
       " 'decoder.fpn_convs.0.bn.weight',\n",
       " 'decoder.fpn_convs.0.bn.bias',\n",
       " 'decoder.fpn_convs.0.bn.running_mean',\n",
       " 'decoder.fpn_convs.0.bn.running_var',\n",
       " 'decoder.fpn_convs.0.bn.num_batches_tracked',\n",
       " 'decoder.fpn_convs.1.conv.weight',\n",
       " 'decoder.fpn_convs.1.bn.weight',\n",
       " 'decoder.fpn_convs.1.bn.bias',\n",
       " 'decoder.fpn_convs.1.bn.running_mean',\n",
       " 'decoder.fpn_convs.1.bn.running_var',\n",
       " 'decoder.fpn_convs.1.bn.num_batches_tracked',\n",
       " 'decoder.fpn_convs.2.conv.weight',\n",
       " 'decoder.fpn_convs.2.bn.weight',\n",
       " 'decoder.fpn_convs.2.bn.bias',\n",
       " 'decoder.fpn_convs.2.bn.running_mean',\n",
       " 'decoder.fpn_convs.2.bn.running_var',\n",
       " 'decoder.fpn_convs.2.bn.num_batches_tracked',\n",
       " 'decoder.fpn_bottleneck.conv.weight',\n",
       " 'decoder.fpn_bottleneck.bn.weight',\n",
       " 'decoder.fpn_bottleneck.bn.bias',\n",
       " 'decoder.fpn_bottleneck.bn.running_mean',\n",
       " 'decoder.fpn_bottleneck.bn.running_var',\n",
       " 'decoder.fpn_bottleneck.bn.num_batches_tracked',\n",
       " 'semseghead_1.1.weight',\n",
       " 'semseghead_1.1.bias',\n",
       " 'semseghead_2.1.weight',\n",
       " 'semseghead_2.1.bias',\n",
       " 'semseghead_3.1.weight',\n",
       " 'semseghead_3.1.bias']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in a['state_dict'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_ = \"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/01.Models/04.SAM_fine/swint_upernet_imp_sep_model.pth\"\n",
    "samrs_model.load_state_dict(torch.load(path_)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "SyncBatchNorm expected input tensor to be on GPU",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dummy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msamrs_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 37\u001b[0m, in \u001b[0;36mSamRS.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m     36\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m---> 37\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     output_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemseghead_1(output)\n\u001b[1;32m     39\u001b[0m     output_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemseghead_2(output)\n",
      "File \u001b[0;32m~/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.tmp_ipy/15.Lab_Detection/01.Models/04.SAM_fine/upper_net_mmseg.py:566\u001b[0m, in \u001b[0;36mUPerHead.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward function.\"\"\"\u001b[39;00m\n\u001b[1;32m    564\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 566\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m#output = self.cls_seg(output)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(output, scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.tmp_ipy/15.Lab_Detection/01.Models/04.SAM_fine/upper_net_mmseg.py:526\u001b[0m, in \u001b[0;36mUPerHead._forward_feature\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_inputs(inputs)\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# build laterals\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m laterals \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    527\u001b[0m     lateral_conv(inputs[i])\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, lateral_conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlateral_convs)\n\u001b[1;32m    529\u001b[0m ]\n\u001b[1;32m    531\u001b[0m laterals\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpsp_forward(inputs))\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# build top-down path\u001b[39;00m\n",
      "File \u001b[0;32m~/.tmp_ipy/15.Lab_Detection/01.Models/04.SAM_fine/upper_net_mmseg.py:527\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    523\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_inputs(inputs)\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# build laterals\u001b[39;00m\n\u001b[1;32m    526\u001b[0m laterals \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 527\u001b[0m     \u001b[43mlateral_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, lateral_conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlateral_convs)\n\u001b[1;32m    529\u001b[0m ]\n\u001b[1;32m    531\u001b[0m laterals\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpsp_forward(inputs))\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# build top-down path\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/mmcv/cnn/bricks/conv_module.py:283\u001b[0m, in \u001b[0;36mConvModule.forward\u001b[0;34m(self, x, activate, norm)\u001b[0m\n\u001b[1;32m    281\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m norm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_norm:\n\u001b[0;32m--> 283\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mact\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m activate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_activation:\n\u001b[1;32m    285\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(x)\n",
      "File \u001b[0;32m~/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:686\u001b[0m, in \u001b[0;36mSyncBatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;66;03m# currently only GPU input is supported\u001b[39;00m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[0;32m--> 686\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSyncBatchNorm expected input tensor to be on GPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_dim(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_non_zero_input_channels(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: SyncBatchNorm expected input tensor to be on GPU"
     ]
    }
   ],
   "source": [
    "dummy = torch.randn(4,3,224,224)\n",
    "samrs_model.forward(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 0 samples in train set.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Size should be int or sequence. Got <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_ \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_git\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mISAIDDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_root\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/00.Data/isaid/TrainData\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.tmp_ipy/15.Lab_Detection/01.Models/04.SAM_fine/dataset_git.py:449\u001b[0m, in \u001b[0;36mISAIDDataset.__init__\u001b[0;34m(self, img_size, split, data_root, transform)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_tensor \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m    442\u001b[0m         T\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m    443\u001b[0m         T\u001b[38;5;241m.\u001b[39mNormalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n\u001b[1;32m    444\u001b[0m     ])\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_tensor \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m    448\u001b[0m         T\u001b[38;5;241m.\u001b[39mToPILImage(),\n\u001b[0;32m--> 449\u001b[0m         \u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    450\u001b[0m         T\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m    451\u001b[0m         T\u001b[38;5;241m.\u001b[39mNormalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n\u001b[1;32m    452\u001b[0m     ])\n",
      "File \u001b[0;32m~/.conda/envs/8.tmp.copied/lib/python3.8/site-packages/torchvision/transforms/transforms.py:321\u001b[0m, in \u001b[0;36mResize.__init__\u001b[0;34m(self, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    319\u001b[0m _log_api_usage_once(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, (\u001b[38;5;28mint\u001b[39m, Sequence)):\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize should be int or sequence. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf size is a sequence, it should have 1 or 2 values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Size should be int or sequence. Got <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "dataset_ = dataset_git.ISAIDDataset(data_root = \"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/00.Data/isaid/TrainData\", split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "8.tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
