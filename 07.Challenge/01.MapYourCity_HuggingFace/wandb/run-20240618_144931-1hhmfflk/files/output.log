[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
INFO: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
INFO:lightning.fabric.utilities.distributed:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k)
INFO:timm.models._hub:[timm/vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO:RS_utils:{'input_size': (3, 336, 336), 'interpolation': 'bicubic', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'crop_pct': 1.0, 'crop_mode': 'squash'}
INFO:RS_utils:Compose(
    Resize(size=(336, 336), interpolation=bicubic, max_size=None, antialias=warn)
    CenterCrop(size=(336, 336))
    ToTensor()
    Normalize(mean=tensor([0.4815, 0.4578, 0.4082]), std=tensor([0.2686, 0.2613, 0.2758]))
)
fabric
INFO:RS_utils:{'epoch': 0, 'iteration': 0, 'progress': 0.0, 'loss': 1.9001, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 1, 'progress': 0.01, 'loss': 2.5898, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 2, 'progress': 0.02, 'loss': 2.9384, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 3, 'progress': 0.04, 'loss': 2.9794, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 4, 'progress': 0.05, 'loss': 3.2734, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 5, 'progress': 0.07, 'loss': 1.6523, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 6, 'progress': 0.08, 'loss': 1.4291, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 7, 'progress': 0.1, 'loss': 2.3017, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 8, 'progress': 0.11, 'loss': 1.7382, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 9, 'progress': 0.13, 'loss': 1.6679, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 10, 'progress': 0.14, 'loss': 2.2851, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 11, 'progress': 0.15, 'loss': 1.9291, 'batch_size': 2, 'lr': 1.953125e-06}
INFO:RS_utils:{'epoch': 0, 'iteration': 12, 'progress': 0.17, 'loss': 2.4921, 'batch_size': 2, 'lr': 1.953125e-06}
Traceback (most recent call last):
  File "/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/07.Challenge/01.MapYourCity_HuggingFace/01.finetune.py", line 124, in <module>
    scaler.step(optimizer)
  File "/mnt/hdd/eric/.conda/envs/mapv2/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py", line 416, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
  File "/mnt/hdd/eric/.conda/envs/mapv2/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py", line 314, in _maybe_opt_step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/mnt/hdd/eric/.conda/envs/mapv2/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py", line 314, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
KeyboardInterrupt