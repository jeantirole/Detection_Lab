#--------------------- config v37
# => learning rate scheduler 
#---------------------


#-------------------------------- This is Test Configuration
# Version 
RUN_VERSION : 41 # aaugmentation trivalaugmentwide appllied 

# Data Type 
DATA_TYPE : sentinel2 #streetview #topview #sentinel2

# K-fold
N_SPLIT: 5
RANDOM_STATE: 99

# DDP                
FABRIC: True
DEVICES: [0,1,2,3]
NUM_WORKERS: 8 

# Single run 
DEVICE: cuda:0

# SAMPLE
SAMPLE : False # Data sampling for test 
SAMPLE_PERCENT : 0.01
MODEL_SAVE : True

# MODEL
TIMM: True
MODEL: eva_large_patch14_336.in22k_ft_in22k_in1k #VAN #eva_large_patch14_336.in22k_ft_in22k_in1k
SAVE_DIR: /mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/07.Challenge/01.MapYourCity_HuggingFace/output


#eva02_base_patch14_448.mim_in22k_ft_in22k_in1k
#eva_large_patch14_336.in22k_ft_in22k_in1k => now best
#beitv2_large_patch16_224.in1k_ft_in22k_in1k => this works 

# TRAIN
# Loss 
LOSS_FN : CE 
LABEL_SMOOTHING : True

# Optimizer & Scheduler 
OPTIMIZER : AdamW 
SCHEDULER : CosineAnnealingWarmRestarts

# Others
CLASSES_NUM : 7
INTERPOLATION: bicubic
EPOCHS: 8                   # number of epochs to train
LEARNING_RATE_CYCLE : 4
BATCH_SIZE: 8            # batch size to use
EVAL_INTERVAL: 1            # evaluation interval
LR : 2.5E-05
# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=2, T_mult=1, eta_min=cfg.LR,gamma=0.5)


# AUGMENTATION
#AUGMENTATIONS: ["griddropout", "horizontalflip","gaussnoise", "blur"] # "verticalFlip", "blur"
AUGMENTATIONS_albumentation: False
AUGMENTATIONS: ["griddropout", "horizontalflip","gaussnoise", "blur"]

AUGMENTATIONS_torchvision: True
AUGMENTATIONS: "trivial"

# LABEL Distribution
LABEL_DEVIATION : 2 