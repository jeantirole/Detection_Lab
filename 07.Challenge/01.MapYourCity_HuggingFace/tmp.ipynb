{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MonostateSingleton object at 0x7f9d00503b50>\n",
      "<__main__.MonostateSingleton object at 0x7f9d00503d90>\n",
      "{'a': 2, 'b': 2, 'c': 0}\n",
      "{'a': 2, 'b': 2, 'c': 0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metric\n",
    "class MonostateSingleton:\n",
    "    __shared_state = {}\n",
    "    def __init__(self):\n",
    "        self.__dict__ = self.__shared_state\n",
    "\n",
    "m1 = MonostateSingleton()\n",
    "m2 = MonostateSingleton()\n",
    "print(m1) # <__main__.MonostateSingleton object at 0x02C4B0E8>\n",
    "print(m2) # <__main__.MonostateSingleton object at 0x02C4B118>\n",
    "\n",
    "m1.a = 1\n",
    "m2.b = 2\n",
    "m2.c = 0\n",
    "m1.a += 1\n",
    "print(m1.__dict__) # {'a': 1, 'b': 2}\n",
    "print(m2.__dict__) # {'a': 1, 'b': 2}x03A6B340>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 4, 'b': 2, 'c': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.a += 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 7, 'b': 2, 'c': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "86\n",
      "172\n",
      "258\n",
      "344\n",
      "430\n",
      "516\n",
      "602\n",
      "688\n",
      "774\n",
      "860\n"
     ]
    }
   ],
   "source": [
    "total = 867\n",
    "for i in range(0,total):\n",
    "    #print(int(total * 0.1))\n",
    "    if i % int((total*0.1)) ==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "0.0\n",
      "1.0\n",
      "2.000000000000001\n",
      "3.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#(progress*100) % 10 == 0:\n",
    "\n",
    "for i in range(0,10):\n",
    "    #print(i)\n",
    "    z = i * 0.01\n",
    "    #print(z)\n",
    "    print( (z * 100) % 5   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ method called but nothing is created\n",
      "None\n",
      "__init__ method called but nothing is created\n",
      "s와 s1은 서로 같은 인스턴스인가? ->  False\n",
      "s1 :  <__main__.LazyInstantiation object at 0x7f9d004cab50>\n",
      "s2 :  <__main__.LazyInstantiation object at 0x7f9d004cab50>\n",
      "instance already created: <__main__.LazyInstantiation object at 0x7f9d004cab50>\n",
      "s3 :  <__main__.LazyInstantiation object at 0x7f9d004cab50>\n"
     ]
    }
   ],
   "source": [
    "class LazyInstantiation:\n",
    "    _instance = None\n",
    "    _shared_data = {\"a\":0}\n",
    "    def __init__(self):\n",
    "        if not LazyInstantiation._instance:\n",
    "            print('__init__ method called but nothing is created')\n",
    "        else:\n",
    "            print('instance already created:', self.getInstance())\n",
    " \n",
    "    @classmethod\n",
    "    def getInstance(cls):\n",
    "        if not cls._instance:\n",
    "            cls._instance = LazyInstantiation()\n",
    "        return cls._instance\n",
    " \n",
    "    def data_update(self,v):\n",
    "        self._shared_data[\"a\"] += v\n",
    "\n",
    "        \n",
    "# __init__ method called but nothing is created\n",
    "s = LazyInstantiation()\n",
    "print(s._instance) # None\n",
    "# __init__ method called but nothing is created\n",
    "s1 = LazyInstantiation.getInstance()\n",
    "s2 = LazyInstantiation.getInstance()\n",
    "print('s와 s1은 서로 같은 인스턴스인가? -> ',s==s1) # True\n",
    "print('s1 : ',s1._instance) # <__main__.LazyInstantiation object at 0x03A6B340>\n",
    "print('s2 : ',s2._instance) # <__main__.LazyInstantiation object at 0x03A6B340>\n",
    " \n",
    "s3 = LazyInstantiation() # instance already created: <__main__.LazyInstantiation object at 0x03A6B340>\n",
    "print('s3 : ',s3._instance) #  <__main__.LazyInstantiation object at 0x03A6B340>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.data_update(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s._shared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.data_update(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 6}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s._shared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 6}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3._shared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.data_update(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3._shared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s._shared_data['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "\n",
    "class Singleton:\n",
    "    _instance = None\n",
    "\n",
    "    def __init__(self, value):\n",
    "        if Singleton._instance is not None:\n",
    "            raise Exception(\"This is a singleton class!\")\n",
    "        self.value = value\n",
    "        Singleton._instance = self\n",
    "\n",
    "    @classmethod\n",
    "    def get_instance(cls):\n",
    "        if cls._instance is None:\n",
    "            raise Exception(\"Instance is not created yet!\")\n",
    "        return cls._instance\n",
    "\n",
    "def create_singleton(value, shared_dict):\n",
    "    singleton = Singleton(value)\n",
    "    shared_dict['singleton'] = singleton.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singleton value: 20\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    manager = Manager()\n",
    "    shared_dict = manager.dict()\n",
    "\n",
    "    p1 = Process(target=create_singleton, args=(10, shared_dict))\n",
    "    p2 = Process(target=create_singleton, args=(20, shared_dict))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "    print(\"Singleton value:\", shared_dict['singleton'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "class Singleton:\n",
    "    _instance = None\n",
    "    _lock = threading.Lock()\n",
    "    _data = {\n",
    "        \"a\" :[]\n",
    "    }\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            with cls._lock:\n",
    "                if cls._instance is None:\n",
    "                    cls._instance = super(Singleton, cls).__new__(cls)\n",
    "        return cls._instance\n",
    "\n",
    "# Example usage\n",
    "singleton1 = Singleton()\n",
    "singleton2 = Singleton()\n",
    "\n",
    "print(singleton1 is singleton2)  # This should print True, indicating both are the same instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleton1._data['a'].append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleton2._data['a'].append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [10, 10]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singleton2._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sentinel test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.10 (you have 1.4.8). Upgrade using: pip install --upgrade albumentations\n",
      "/mnt/hdd/eric/.conda/envs/mapv2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This integration is tested and supported for lightning Fabric 2.1.3.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.\n"
     ]
    }
   ],
   "source": [
    "#---\n",
    "\n",
    "'''\n",
    "01.22\n",
    "sentinel2 \n",
    "64x64 => 224x224 \n",
    "\n",
    "\n",
    "path note 01.20\n",
    "holdout => k-fold ! \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#--\n",
    "import sys\n",
    "sys.path.append(\"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/07.Challenge/01.MapYourCity_HuggingFace\")\n",
    "import map_dataset\n",
    "import map_train\n",
    "from models import *\n",
    "\n",
    "sys.path.append(\"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/00.Libs\")\n",
    "import RS_dataset\n",
    "import RS_models\n",
    "import RS_utils\n",
    "#--- torch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "#--- loss functions\n",
    "from utils.losses import LabelSmoothCrossEntropy, CrossEntropyLoss\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "#---\n",
    "from lightning.fabric import Fabric\n",
    "from lightning.fabric.loggers import CSVLogger, TensorBoardLogger\n",
    "from torchmetrics.classification import Accuracy\n",
    "import pandas as pd \n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import argparse\n",
    "import yaml \n",
    "import timm\n",
    "import numpy as np \n",
    "import time\n",
    "import wandb\n",
    "from rich.console import Console\n",
    "from wandb.integration.lightning.fabric import WandbLogger\n",
    "\n",
    "\n",
    "\n",
    "#--- argparser\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--cfg', type=str, \\\n",
    "                    default='/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/07.Challenge/01.MapYourCity_HuggingFace/configs/finetune_22.yaml')\n",
    "args = parser.parse_args([])\n",
    "cfg = argparse.Namespace(**yaml.load(open(args.cfg), Loader=yaml.SafeLoader))\n",
    "\n",
    "#--- Data \n",
    "input_path = \"/mnt/hdd/eric/.tmp_ipy/00.Data/Map_Your_City/building-age-dataset/\"\n",
    "train_path = input_path + \"train/data/\"\n",
    "test_path = input_path + \"test/data/\"\n",
    "train_df = pd.read_csv(input_path + \"train/train-set.csv\")\n",
    "test_df = pd.read_csv(input_path + \"test/test-set.csv\") \n",
    "\n",
    "#--- data split \n",
    "names_data = sorted( os.listdir(train_path) )\n",
    "\n",
    "names_label = []\n",
    "for ID in names_data:\n",
    "    y = int(open(train_path + ID + '/label.txt', \"r\").read())\n",
    "    names_label.append(y)\n",
    "\n",
    "if cfg.SAMPLE:\n",
    "    parse_idx = int(len(names_data) * cfg.SAMPLE_PERCENT)\n",
    "    names_data = names_data[:parse_idx]\n",
    "    names_label = names_label[:parse_idx]\n",
    "\n",
    "\n",
    "#-- kfold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd/eric/.conda/envs/mapv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': (3, 448, 448), 'interpolation': 'bicubic', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'crop_pct': 1.0, 'crop_mode': 'squash'}\n"
     ]
    }
   ],
   "source": [
    "#--- model\n",
    "model = timm.create_model(\n",
    "cfg.MODEL,\n",
    "pretrained=True,\n",
    "num_classes=cfg.CLASSES_NUM ) \n",
    "\n",
    "#--- data config and transform\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "data_transform = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "print(data_config)\n",
    "\n",
    "#--- train and valid selection need\n",
    "train_set = map_dataset.Map_Dataset_v12(names_data,train_path,max_size=data_config['input_size'][1],cfg=cfg,split='train') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,x3, y,y  = train_set.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7583, -1.7583, -1.7583,  ..., -1.1589, -1.1589, -1.1589],\n",
       "         [-1.7583, -1.7583, -1.7583,  ..., -1.1589, -1.1589, -1.1589],\n",
       "         [-1.7583, -1.7583, -1.7583,  ..., -1.1589, -1.1589, -1.1589],\n",
       "         ...,\n",
       "         [ 0.4508,  0.4508,  0.4508,  ..., -1.1247, -1.1247, -1.1247],\n",
       "         [ 0.4508,  0.4508,  0.4508,  ..., -1.1247, -1.1247, -1.1247],\n",
       "         [ 0.4508,  0.4508,  0.4508,  ..., -1.1247, -1.1247, -1.1247]],\n",
       "\n",
       "        [[-1.2304, -1.2304, -1.2304,  ..., -1.0028, -1.0028, -1.0028],\n",
       "         [-1.2304, -1.2304, -1.2304,  ..., -1.0028, -1.0028, -1.0028],\n",
       "         [-1.2304, -1.2304, -1.2304,  ..., -1.0028, -1.0028, -1.0028],\n",
       "         ...,\n",
       "         [ 0.5028,  0.5028,  0.5028,  ..., -1.2129, -1.2129, -1.2129],\n",
       "         [ 0.5028,  0.5028,  0.5028,  ..., -1.2129, -1.2129, -1.2129],\n",
       "         [ 0.5028,  0.5028,  0.5028,  ..., -1.2129, -1.2129, -1.2129]],\n",
       "\n",
       "        [[-1.6127, -1.6127, -1.6127,  ..., -1.2641, -1.2641, -1.2641],\n",
       "         [-1.6127, -1.6127, -1.6127,  ..., -1.2641, -1.2641, -1.2641],\n",
       "         [-1.6127, -1.6127, -1.6127,  ..., -1.2641, -1.2641, -1.2641],\n",
       "         ...,\n",
       "         [-0.2358, -0.2358, -0.2358,  ..., -1.3164, -1.3164, -1.3164],\n",
       "         [-0.2358, -0.2358, -0.2358,  ..., -1.3164, -1.3164, -1.3164],\n",
       "         [-0.2358, -0.2358, -0.2358,  ..., -1.3164, -1.3164, -1.3164]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[[ 21,  46,  11],\n",
    "#         [ 17,  41,  10],\n",
    "#         [ 17,  36,  10],\n",
    "#         ...,\n",
    "#         [ 47,  52,  25],\n",
    "#         [ 42,  53,  24],\n",
    "#         [ 56,  59,  31]],\n",
    "\n",
    "#        [[ 13,  30,   8],\n",
    "#         [  9,  24,   4],\n",
    "#         [ 12,  20,   5],\n",
    "#         ...,\n",
    "#         [ 19,  34,  11],\n",
    "#         [ 19,  36,  12],\n",
    "#         [ 33,  48,  19]],\n",
    "\n",
    "#        [[ 12,  19,   5],\n",
    "#         [ 12,  19,   5],\n",
    "#         [ 15,  23,   8],\n",
    "#         ...,\n",
    "#         [ 42,  52,  26],\n",
    "#         [ 40,  52,  26],\n",
    "#         [ 20,  47,  16]],\n",
    "\n",
    "#        ...,\n",
    "# ...\n",
    "#         [ 52,  57,  31],\n",
    "#         ...,\n",
    "#         [ 80,  71,  38],\n",
    "#         [ 61,  49,  31],\n",
    "#         [ 58,  47,  28]]], dtype=int16)\n",
    "# Output is truncated. View as a scrollable element or op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
