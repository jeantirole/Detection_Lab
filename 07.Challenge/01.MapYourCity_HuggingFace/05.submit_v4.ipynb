{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "- ensembel CE models (last fc layer)   \n",
    "15 models (street, top, sentinel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.11 (you have 1.4.8). Upgrade using: pip install --upgrade albumentations\n",
      "/mnt/hdd/eric/.conda/envs/mapv2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#--\n",
    "import sys\n",
    "sys.path.append(\"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/07.Challenge/01.MapYourCity_HuggingFace\")\n",
    "import map_dataset\n",
    "import map_train\n",
    "from models import *\n",
    "\n",
    "sys.path.append(\"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/00.Libs\")\n",
    "import RS_dataset\n",
    "import RS_models\n",
    "import RS_utils\n",
    "#--- torch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "#--- loss functions\n",
    "from utils.losses import LabelSmoothCrossEntropy, CrossEntropyLoss\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "#---\n",
    "from lightning.fabric import Fabric\n",
    "from lightning.fabric.loggers import CSVLogger, TensorBoardLogger\n",
    "from torchmetrics.classification import Accuracy\n",
    "import pandas as pd \n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "import yaml \n",
    "import timm\n",
    "import numpy as np \n",
    "import time\n",
    "import wandb\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from rich.console import Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model run version :  33\n",
      "Model run fold :  0\n",
      "Data type :  streetview\n",
      "Model run version :  33\n",
      "Model run fold :  1\n",
      "Data type :  streetview\n",
      "Model run version :  33\n",
      "Model run fold :  2\n",
      "Data type :  streetview\n",
      "Model run version :  33\n",
      "Model run fold :  3\n",
      "Data type :  streetview\n",
      "Model run version :  33\n",
      "Model run fold :  4\n",
      "Data type :  streetview\n",
      "Model run version :  32\n",
      "Model run fold :  0\n",
      "Data type :  topview\n",
      "Model run version :  32\n",
      "Model run fold :  1\n",
      "Data type :  topview\n",
      "Model run version :  32\n",
      "Model run fold :  2\n",
      "Data type :  topview\n",
      "Model run version :  32\n",
      "Model run fold :  3\n",
      "Data type :  topview\n",
      "Model run version :  32\n",
      "Model run fold :  4\n",
      "Data type :  topview\n",
      "Model run version :  34\n",
      "Model run fold :  0\n",
      "Data type :  sentinel2\n",
      "Model run version :  34\n",
      "Model run fold :  1\n",
      "Data type :  sentinel2\n",
      "Model run version :  34\n",
      "Model run fold :  2\n",
      "Data type :  sentinel2\n",
      "Model run version :  34\n",
      "Model run fold :  3\n",
      "Data type :  sentinel2\n",
      "Model run version :  34\n",
      "Model run fold :  4\n",
      "Data type :  sentinel2\n"
     ]
    }
   ],
   "source": [
    "#--- all infos\n",
    "inference_dict ={\n",
    "    'models':[],\n",
    "    'folds' :[],\n",
    "    'data' :[],\n",
    "    'cfgs':[],\n",
    "    'predictions':[],\n",
    "    'labels':[]\n",
    "}\n",
    "\n",
    "#--- argparser\n",
    "cfgs_names = ['finetune_21.yaml', 'finetune_20.yaml','finetune_22.yaml']\n",
    "for cfg_name in cfgs_names:    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--cfg', type=str, default=os.path.join('/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/07.Challenge/01.MapYourCity_HuggingFace/configs', cfg_name))\n",
    "    args = parser.parse_args(args=[])\n",
    "    cfg = argparse.Namespace(**yaml.load(open(args.cfg), Loader=yaml.SafeLoader))\n",
    "    \n",
    "    for fold_ in range(cfg.N_SPLIT):        \n",
    "        inference_dict['cfgs'].append(cfg)\n",
    "        inference_dict['folds'].append(fold_)\n",
    "        inference_dict['data'].append(cfg.DATA_TYPE)\n",
    "        print(\"Model run version : \", cfg.RUN_VERSION)\n",
    "        print(\"Model run fold : \", fold_)\n",
    "        print(\"Data type : \", cfg.DATA_TYPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Data \n",
    "input_path = \"/mnt/hdd/eric/.tmp_ipy/00.Data/Map_Your_City/building-age-dataset/\"\n",
    "train_path = input_path + \"train/data/\"\n",
    "test_path = input_path + \"test/data/\"\n",
    "train_df = pd.read_csv(input_path + \"train/train-set.csv\")\n",
    "test_df = pd.read_csv(input_path + \"test/test-set.csv\") \n",
    "\n",
    "#--- data split \n",
    "names_data = sorted( os.listdir(train_path) )\n",
    "\n",
    "names_label = []\n",
    "for ID in names_data:\n",
    "    y = int(open(train_path + ID + '/label.txt', \"r\").read())\n",
    "    names_label.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd/eric/.conda/envs/mapv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k)\n",
      "INFO:timm.models._hub:[timm/eva02_base_patch14_448.mim_in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------------------\n",
      " Model Name :  eva02_base_patch14_448.mim_in22k_ft_in22k_in1k\n"
     ]
    }
   ],
   "source": [
    "for cfg in inference_dict['cfgs']:   \n",
    "    model = timm.create_model(\n",
    "    cfg.MODEL,\n",
    "    pretrained=True,\n",
    "    num_classes=cfg.CLASSES_NUM )\n",
    "\n",
    "    #--- data config and transform\n",
    "    data_config = timm.data.resolve_model_data_config(model)\n",
    "    data_transform = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "    inference_dict['models'].append(model)\n",
    "    print(\"#------------------------------------\")\n",
    "    print(\" Model Name : \",cfg.MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--- all the candidates for ensembles based on validation score \n",
    "\n",
    "saved_root = \"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/07.Challenge/01.MapYourCity_HuggingFace/output\"\n",
    "check_points = sorted(os.listdir(saved_root))\n",
    "target_runs = list(set([ cfg.RUN_VERSION for cfg in inference_dict['cfgs']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_model(target_run_n):\n",
    "    \n",
    "    target_runs_0 = [i for i in check_points if str(i.split(\"_\")[0]) == str(target_run_n) ]\n",
    "    \n",
    "    best_model_runs = []\n",
    "    for fold_n in range(0,cfg.N_SPLIT):\n",
    "        fold_s = [ i for i in target_runs_0 if str(i.split(\"_\")[-5]) == str(fold_n) ]\n",
    "        #print(fold_s)\n",
    "        best_model = \"\"\n",
    "        best_score = 0\n",
    "        for fq in fold_s:\n",
    "            score =  float(fq.split(\"_\")[-3])\n",
    "            if score > best_score:\n",
    "                score = best_score\n",
    "                best_model = fq\n",
    "        best_model_runs.append(best_model)\n",
    "    return best_model_runs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_streetview_CE_fold_0_recall_0.6706_epoch_9.pth\n",
      "33_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_streetview_CE_fold_1_recall_0.6744_epoch_3.pth\n",
      "33_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_streetview_CE_fold_2_recall_0.6665_epoch_9.pth\n",
      "33_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_streetview_CE_fold_3_recall_0.6531_epoch_5.pth\n",
      "33_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_streetview_CE_fold_4_recall_0.6697_epoch_2.pth\n",
      "32_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_topview_CE_fold_0_recall_0.6837_epoch_4.pth\n",
      "32_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_topview_CE_fold_1_recall_0.6871_epoch_8.pth\n",
      "32_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_topview_CE_fold_2_recall_0.6879_epoch_6.pth\n",
      "32_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_topview_CE_fold_3_recall_0.6631_epoch_8.pth\n",
      "32_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_topview_CE_fold_4_recall_0.6958_epoch_7.pth\n",
      "34_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_sentinel2_CE_fold_0_recall_0.6294_epoch_4.pth\n",
      "34_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_sentinel2_CE_fold_1_recall_0.6245_epoch_4.pth\n",
      "34_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_sentinel2_CE_fold_2_recall_0.6236_epoch_3.pth\n",
      "34_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_sentinel2_CE_fold_3_recall_0.6083_epoch_4.pth\n",
      "34_eva02_base_patch14_448.mim_in22k_ft_in22k_in1k_sentinel2_CE_fold_4_recall_0.6270_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "#--- find all \n",
    "global_best_models = []\n",
    "for tg in target_runs:\n",
    "    fold_best_models = find_best_model(tg)\n",
    "    global_best_models.extend(fold_best_models)\n",
    "\n",
    "\n",
    "# Define the categories in the desired order\n",
    "categories = ['streetview', 'topview', 'sentinel2']\n",
    "\n",
    "# Create a dictionary to hold lists of file paths for each category\n",
    "categorized_files = {category: [] for category in categories}\n",
    "\n",
    "# Categorize the file paths\n",
    "for path in global_best_models:\n",
    "    for category in categories:\n",
    "        if category in path:\n",
    "            categorized_files[category].append(path)\n",
    "            break\n",
    "\n",
    "# Reorder the file paths based on the desired order\n",
    "ordered_file_paths = []\n",
    "for category in categories:\n",
    "    ordered_file_paths.extend(categorized_files[category])\n",
    "\n",
    "# Print the ordered file paths\n",
    "for path in ordered_file_paths:\n",
    "    print(path)\n",
    "\n",
    "\n",
    "ckpt_paths =[ os.path.join(saved_root,i) for i in ordered_file_paths]\n",
    "for i,model in enumerate(inference_dict['models']):\n",
    "    model.load_state_dict(torch.load(ckpt_paths[i])['model'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = map_dataset.Map_Dataset_v7(names_data,train_path,max_size=data_config['input_size'][1],cfg=cfg,split=\"valid\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
