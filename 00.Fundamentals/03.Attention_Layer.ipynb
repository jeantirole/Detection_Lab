{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Attention\n",
    "\n",
    "- multi-head self-attention\n",
    "- equation\n",
    "\n",
    "attn = softmax(q @ k.t)\n",
    "result = attn @ v \n",
    "\n",
    "mixed_q = softmax( (4,10) @ (10,4) ) @ v \n",
    "\n",
    "- engineering \n",
    "\n",
    "head 마다 w 를 따로 만들어주었음  \n",
    "nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code ref : https://medium.com/mlearning-ai/vision-transformers-from-scratch-pytorch-a-step-by-step-guide-96c3313c2e0c\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyMSA(nn.Module):\n",
    "    def __init__(self, d, n_heads=2):\n",
    "        super(MyMSA, self).__init__()\n",
    "        self.d = d\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        assert d % n_heads == 0, f\"Can't divide dimension {d} into {n_heads} heads\"\n",
    "\n",
    "        d_head = int(d / n_heads)\n",
    "        self.q_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.k_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.v_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.d_head = d_head\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        # Sequences has shape (N, seq_length, token_dim)\n",
    "        # We go into shape    (N, seq_length, n_heads, token_dim / n_heads)\n",
    "        # And come back to    (N, seq_length, item_dim)  (through concatenation)\n",
    "        result = []\n",
    "        for sequence in sequences:\n",
    "            seq_result = []\n",
    "            for head in range(self.n_heads):\n",
    "                q_mapping = self.q_mappings[head]\n",
    "                k_mapping = self.k_mappings[head]\n",
    "                v_mapping = self.v_mappings[head]\n",
    "\n",
    "                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n",
    "                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n",
    "\n",
    "                print(\"q shape\", q.shape)\n",
    "                print(\"k shape\", k.shape)\n",
    "                print(\"v shape\", v.shape)\n",
    "\n",
    "                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n",
    "                \n",
    "                print(\"attention shape\", attention.shape)\n",
    "\n",
    "                seq_result.append(attention @ v)\n",
    "            result.append(torch.hstack(seq_result))\n",
    "        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ = torch.randn((1,4,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSA = MyMSA(d=10,n_heads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q shape torch.Size([4, 10])\n",
      "k shape torch.Size([4, 10])\n",
      "v shape torch.Size([4, 10])\n",
      "attention shape torch.Size([4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2914, -0.3380, -0.1037, -0.3091,  0.2320,  0.3522,  0.0466,\n",
       "          -0.5097,  0.3001, -0.1115],\n",
       "         [ 0.3803, -0.2434, -0.2613, -0.2943,  0.1425,  0.3373,  0.0014,\n",
       "          -0.6945,  0.4082, -0.0787],\n",
       "         [-0.0247, -0.5951,  0.1316, -0.2992,  0.3529,  0.3853,  0.1303,\n",
       "          -0.1537,  0.1337, -0.1963],\n",
       "         [-0.0714, -0.6603,  0.4050, -0.3395,  0.4705,  0.4381,  0.1973,\n",
       "           0.1237, -0.0513, -0.2108]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSA.forward(a_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "8.tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
