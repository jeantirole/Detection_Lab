{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n",
      "tensor([[3],\n",
      "        [7],\n",
      "        [4],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ref : https://medium.com/@mbednarski/understanding-indexing-with-pytorch-gather-33717a84ebc4\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "indices = torch.LongTensor([3,7,4,1])\n",
    "indices = indices.unsqueeze(-1)\n",
    "print(indices.shape)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]])\n"
     ]
    }
   ],
   "source": [
    "target = torch.arange(0,40).unsqueeze(0)\n",
    "target_ = target.reshape(4,-1)\n",
    "print(target_.shape)\n",
    "print(target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntorch.gather(input, dim, index, out=None, sparse_grad=False) → Tensor\\nGathers values along an axis specified by dim.\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "torch.gather(input, dim, index, out=None, sparse_grad=False) → Tensor\n",
    "Gathers values along an axis specified by dim.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3],\n",
       "        [17],\n",
       "        [24],\n",
       "        [31]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(input=target_, dim=1, index=indices )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3D example\\n\\nIn three dimensions, things become more tricky.\\n\\nImagine we have a following scenario: RNN network with sequences padded to maximum length. \\nWe would like to collect last element in each sequence, with all features from rnn hidden state.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3D example\n",
    "\n",
    "In three dimensions, things become more tricky.\n",
    "\n",
    "Imagine we have a following scenario: RNN network with sequences padded to maximum length. \n",
    "We would like to collect last element in each sequence, with all features from rnn hidden state.\n",
    "\n",
    "BATCH_SIZE x MAX_SEQ_LEN x HIDDEN_STAT\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0., 100., 200., 300., 400., 500.],\n",
      "         [ 10., 110., 210., 310., 410., 510.],\n",
      "         [ 20., 120., 220., 320., 420., 520.],\n",
      "         [ 30., 130., 230., 330., 430., 530.],\n",
      "         [ 40., 140., 240., 340., 440., 540.],\n",
      "         [ 50., 150., 250., 350., 450., 550.],\n",
      "         [ 60., 160., 260., 360., 460., 560.],\n",
      "         [ 70., 170., 270., 370., 470., 570.],\n",
      "         [ 80., 180., 280., 380., 480., 580.]],\n",
      "\n",
      "        [[  1., 101., 201., 301., 401., 501.],\n",
      "         [ 11., 111., 211., 311., 411., 511.],\n",
      "         [ 21., 121., 221., 321., 421., 521.],\n",
      "         [ 31., 131., 231., 331., 431., 531.],\n",
      "         [ 41., 141., 241., 341., 441., 541.],\n",
      "         [ 51., 151., 251., 351., 451., 551.],\n",
      "         [ 61., 161., 261., 361., 461., 561.],\n",
      "         [ 71., 171., 271., 371., 471., 571.],\n",
      "         [ 81., 181., 281., 381., 481., 581.]],\n",
      "\n",
      "        [[  2., 102., 202., 302., 402., 502.],\n",
      "         [ 12., 112., 212., 312., 412., 512.],\n",
      "         [ 22., 122., 222., 322., 422., 522.],\n",
      "         [ 32., 132., 232., 332., 432., 532.],\n",
      "         [ 42., 142., 242., 342., 442., 542.],\n",
      "         [ 52., 152., 252., 352., 452., 552.],\n",
      "         [ 62., 162., 262., 362., 462., 562.],\n",
      "         [ 72., 172., 272., 372., 472., 572.],\n",
      "         [ 82., 182., 282., 382., 482., 582.]],\n",
      "\n",
      "        [[  3., 103., 203., 303., 403., 503.],\n",
      "         [ 13., 113., 213., 313., 413., 513.],\n",
      "         [ 23., 123., 223., 323., 423., 523.],\n",
      "         [ 33., 133., 233., 333., 433., 533.],\n",
      "         [ 43., 143., 243., 343., 443., 543.],\n",
      "         [ 53., 153., 253., 353., 453., 553.],\n",
      "         [ 63., 163., 263., 363., 463., 563.],\n",
      "         [ 73., 173., 273., 373., 473., 573.],\n",
      "         [ 83., 183., 283., 383., 483., 583.]],\n",
      "\n",
      "        [[  4., 104., 204., 304., 404., 504.],\n",
      "         [ 14., 114., 214., 314., 414., 514.],\n",
      "         [ 24., 124., 224., 324., 424., 524.],\n",
      "         [ 34., 134., 234., 334., 434., 534.],\n",
      "         [ 44., 144., 244., 344., 444., 544.],\n",
      "         [ 54., 154., 254., 354., 454., 554.],\n",
      "         [ 64., 164., 264., 364., 464., 564.],\n",
      "         [ 74., 174., 274., 374., 474., 574.],\n",
      "         [ 84., 184., 284., 384., 484., 584.]],\n",
      "\n",
      "        [[  5., 105., 205., 305., 405., 505.],\n",
      "         [ 15., 115., 215., 315., 415., 515.],\n",
      "         [ 25., 125., 225., 325., 425., 525.],\n",
      "         [ 35., 135., 235., 335., 435., 535.],\n",
      "         [ 45., 145., 245., 345., 445., 545.],\n",
      "         [ 55., 155., 255., 355., 455., 555.],\n",
      "         [ 65., 165., 265., 365., 465., 565.],\n",
      "         [ 75., 175., 275., 375., 475., 575.],\n",
      "         [ 85., 185., 285., 385., 485., 585.]],\n",
      "\n",
      "        [[  6., 106., 206., 306., 406., 506.],\n",
      "         [ 16., 116., 216., 316., 416., 516.],\n",
      "         [ 26., 126., 226., 326., 426., 526.],\n",
      "         [ 36., 136., 236., 336., 436., 536.],\n",
      "         [ 46., 146., 246., 346., 446., 546.],\n",
      "         [ 56., 156., 256., 356., 456., 556.],\n",
      "         [ 66., 166., 266., 366., 466., 566.],\n",
      "         [ 76., 176., 276., 376., 476., 576.],\n",
      "         [ 86., 186., 286., 386., 486., 586.]],\n",
      "\n",
      "        [[  7., 107., 207., 307., 407., 507.],\n",
      "         [ 17., 117., 217., 317., 417., 517.],\n",
      "         [ 27., 127., 227., 327., 427., 527.],\n",
      "         [ 37., 137., 237., 337., 437., 537.],\n",
      "         [ 47., 147., 247., 347., 447., 547.],\n",
      "         [ 57., 157., 257., 357., 457., 557.],\n",
      "         [ 67., 167., 267., 367., 467., 567.],\n",
      "         [ 77., 177., 277., 377., 477., 577.],\n",
      "         [ 87., 187., 287., 387., 487., 587.]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "max_seq_len = 9\n",
    "hidden_size = 6\n",
    "x = torch.empty(batch_size, max_seq_len, hidden_size)\n",
    "for i in range(batch_size):\n",
    "  for j in range(max_seq_len):\n",
    "    for k in range(hidden_size):\n",
    "      x[i,j,k] = i + j*10 + k*100\n",
    "\n",
    "print(x)\n",
    "\n",
    "# value “123” means “1st batch, 2nd sequence element, 3rd hidden state”. If we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n",
      "torch.Size([8, 6])\n",
      "tensor([[5, 5, 5, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6, 6],\n",
      "        [1, 1, 1, 1, 1, 1],\n",
      "        [8, 8, 8, 8, 8, 8],\n",
      "        [3, 3, 3, 3, 3, 3],\n",
      "        [7, 7, 7, 7, 7, 7],\n",
      "        [3, 3, 3, 3, 3, 3],\n",
      "        [4, 4, 4, 4, 4, 4]])\n"
     ]
    }
   ],
   "source": [
    "lens = torch.LongTensor([5,6,1,8,3,7,3,4])\n",
    "# add one trailing dimension\n",
    "lens = lens.unsqueeze(-1)\n",
    "print(lens.shape)\n",
    "\n",
    "# repeat 6 times\n",
    "indices = lens.repeat(1,6)\n",
    "print(indices.shape)\n",
    "\n",
    "print(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "indices = indices.unsqueeze(1)\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "results = torch.gather(x, 1, indices)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 50., 150., 250., 350., 450., 550.]],\n",
       "\n",
       "        [[ 61., 161., 261., 361., 461., 561.]],\n",
       "\n",
       "        [[ 12., 112., 212., 312., 412., 512.]],\n",
       "\n",
       "        [[ 83., 183., 283., 383., 483., 583.]],\n",
       "\n",
       "        [[ 34., 134., 234., 334., 434., 534.]],\n",
       "\n",
       "        [[ 75., 175., 275., 375., 475., 575.]],\n",
       "\n",
       "        [[ 36., 136., 236., 336., 436., 536.]],\n",
       "\n",
       "        [[ 47., 147., 247., 347., 447., 547.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "8.tmp.copied",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
