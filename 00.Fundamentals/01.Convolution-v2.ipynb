{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# make convolution ! \n",
    "#----------------------------\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- conv ! \n",
    "\n",
    "#-- hypes\n",
    "filter_size = 3 \n",
    "stride = 1 \n",
    "padding = 1 \n",
    "input_channel = 3\n",
    "output_channel = 2\n",
    "img_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[206., 216., 243., ..., 166., 193., 186.],\n",
       "       [235., 205., 166., ..., 142., 192., 196.],\n",
       "       [178., 231., 184., ..., 147., 176., 190.],\n",
       "       ...,\n",
       "       [216., 236., 162., ..., 207., 166., 191.],\n",
       "       [200., 206., 153., ..., 148., 175., 233.],\n",
       "       [181., 224., 156., ...,  99.,  96., 157.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Convolution implementation\n",
    "\n",
    "output_feature_map_shape = (dummy_img.shape[0]-filter_size-1, dummy_img.shape[1]-filter_size-1) / stride\n",
    "\n",
    "\n",
    "'''\n",
    "#--- data , weights\n",
    "dummy_img = np.random.randint(0,10,(img_size,img_size))\n",
    "conv_weight = np.random.randint(0,10,(3,3))\n",
    "z = np.zeros(( int( (dummy_img.shape[0]-filter_size-1)/stride), int((dummy_img.shape[1]-filter_size-1)/stride) ))\n",
    "\n",
    "\n",
    "#--- padding \n",
    "# empty_size = dummy_img.shape[0] + (padding * 2)\n",
    "# empty_zeros = np.zeros( (empty_size,empty_size) )\n",
    "\n",
    "# step = stride = 1 \n",
    "# width - kernel_size - 1 \n",
    "for w_i in range(0, dummy_img.shape[0]-filter_size-1, stride):\n",
    "    for h_i in range(0, dummy_img.shape[1]-filter_size-1, stride):\n",
    "        b = dummy_img[w_i:w_i+filter_size, h_i:h_i+filter_size]\n",
    "        z[w_i,h_i] = np.sum( conv_weight * b )       \n",
    "        \n",
    "display(z.shape)\n",
    "display(z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "8.tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
