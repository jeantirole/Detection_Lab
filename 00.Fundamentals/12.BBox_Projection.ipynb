{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def project_bboxes(bboxes, width_scale_factor, height_scale_factor, mode='a2p'):\n",
    "    assert mode in ['a2p', 'p2a']\n",
    "    \n",
    "    batch_size = bboxes.size(dim=0)\n",
    "    proj_bboxes = bboxes.clone().reshape(batch_size, -1, 4)\n",
    "    invalid_bbox_mask = (proj_bboxes == -1) # indicating padded bboxes\n",
    "    \n",
    "    if mode == 'a2p':\n",
    "        # activation map to pixel image\n",
    "        proj_bboxes[:, :, [0, 2]] *= width_scale_factor\n",
    "        proj_bboxes[:, :, [1, 3]] *= height_scale_factor\n",
    "    else:\n",
    "        # pixel image to activation map\n",
    "        proj_bboxes[:, :, [0, 2]] /= width_scale_factor\n",
    "        proj_bboxes[:, :, [1, 3]] /= height_scale_factor\n",
    "        \n",
    "    proj_bboxes.masked_fill_(invalid_bbox_mask, -1) # fill padded bboxes back with -1\n",
    "    proj_bboxes.resize_as_(bboxes)\n",
    "    \n",
    "    return proj_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_ = torch.tensor([[[145.6544, 288.0000, 322.2210, 445.2000],\n",
    "         [ 97.6091,  14.4000, 510.7989, 597.6000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
    "\n",
    "        [[265.8000, 240.0000, 347.4000, 361.2000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
    "\n",
    "        [[147.6000, 261.0000, 258.0000, 309.0000],\n",
    "         [286.8000, 262.2000, 368.4000, 321.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000],\n",
    "         [ -1.0000,  -1.0000,  -1.0000,  -1.0000]],\n",
    "\n",
    "        [[ 15.6000, 429.0468, 100.8000, 490.2217],\n",
    "         [434.4000, 451.8374, 600.0000, 522.6084],\n",
    "         [282.0000, 449.4384, 400.8000, 505.8153],\n",
    "         [210.0000, 448.2389, 302.4000, 492.6207],\n",
    "         [166.8000, 439.8424, 226.8000, 486.6232],\n",
    "         [129.6000, 445.8399, 180.0000, 479.4261],\n",
    "         [100.8000, 443.4409, 145.2000, 475.8276]]], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.tensor([[1,1,3],\n",
    "                      [4,5,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (sample == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_sample = sample.masked_fill(mask, -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10, -10,   3],\n",
       "        [  4,   5, -10]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd/eric/.conda/envs/a.samrs/lib/python3.8/site-packages/torch/_tensor.py:769: UserWarning: non-inplace resize_as is deprecated\n",
      "  warnings.warn(\"non-inplace resize_as is deprecated\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-10, -10,   3],\n",
       "        [  4,   5, -10]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_sample.resize_as(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a.samrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
