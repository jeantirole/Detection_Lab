{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 768, 28, 14])\n",
      "x shape  torch.Size([1, 384, 28, 14])\n",
      "torch.Size([1, 128, 28, 14])\n",
      "torch.Size([1, 128, 28, 14])\n",
      "torch.Size([1, 128, 28, 14])\n",
      "concat torch.Size([1, 384, 28, 14])\n",
      "#---------------------\n",
      "Output shape: torch.Size([1, 384, 28, 14])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MDCBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,  d1, d2, d3):\n",
    "        super(MDCBlock, self).__init__()\n",
    "\n",
    "        # Pre-Channel Mixer (Point-wise convolution)\n",
    "        self.pre_mixer = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "        # Dilated Convolutional Layers\n",
    "        self.dcl1 = nn.Conv2d(out_channels//3, out_channels//3, kernel_size=3, dilation=d1, padding=d1)\n",
    "\t\t\t\t# dilation => d2\n",
    "        self.dcl2 = nn.Conv2d(out_channels//3, out_channels//3, kernel_size=3, dilation=d2, padding=d2)\n",
    "        # dilation => d3 \n",
    "        self.dcl3 = nn.Conv2d(out_channels//3, out_channels//3, kernel_size=3, dilation=d3, padding=d3)\n",
    "\n",
    "\n",
    "        # Post-Channel Mixer\n",
    "        self.post_mixer = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\t\t\t\t\n",
    "\t\t\t\t# channel wise concat x \n",
    "\t\n",
    "        # Pre-Channel Mixer\n",
    "        x = self.pre_mixer(x)\n",
    "        print(\"x shape \", x.shape)\n",
    "        #x shape  torch.Size([1, 64, 32, 32])\n",
    "        x1 = x[:,0:out_channels//3 * 1 ,:,:] \n",
    "        x2 = x[:,out_channels//3 * 1 : out_channels//3 * 2,:,:]\n",
    "        x3 = x[:,out_channels//3 * 2 : out_channels//3 * 3,:,:]\n",
    "\n",
    "        print(x1.shape)\n",
    "        print(x2.shape)\n",
    "        print(x3.shape)\n",
    "        # Dilated Convolutional Layers\n",
    "        dcl1_out = self.dcl1(x1)\n",
    "        dcl2_out = self.dcl2(x2)\n",
    "        dcl3_out = self.dcl3(x3)\n",
    "\n",
    "        # Concatenate the outputs along the channel dimension\n",
    "        x = torch.cat([dcl1_out, dcl2_out, dcl3_out], dim=1)\n",
    "\n",
    "        print(\"concat\",x.shape)\n",
    "        # Post-Channel Mixer\n",
    "        x = self.post_mixer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "# Assuming input tensor x has shape (batch_size, in_channels, height, width)\n",
    "# and you want to obtain output channels out_channels with receptive fields r1, r2, r3 and dilation rates d1, d2, d3\n",
    "#in_channels = 32 # encoder output == ( 1, 56, 28, 1024 ) x 4 \n",
    "#out_channels = 64  \n",
    "d1, d2, d3 = 3, 5, 7\n",
    "#x = torch.randn(1, in_channels, 896, 448)  # Example input tensor\n",
    "\n",
    "in_channels = 768\n",
    "out_channels = 384\n",
    "\n",
    "x = torch.randn(1, 768, 28, 14)\n",
    "print(\"Input shape:\", x.shape)\n",
    "mdc_block = MDCBlock(in_channels, out_channels, d1, d2, d3)\n",
    "output = mdc_block(x)\n",
    "print(\"#---------------------\")\n",
    "print(\"Output shape:\", output.shape)  # Output shape will depend on the input size and parameters of the block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 768, 28, 14])\n",
      "x shape  torch.Size([1, 384, 28, 14])\n",
      "torch.Size([1, 128, 28, 14])\n",
      "torch.Size([1, 128, 28, 14])\n",
      "torch.Size([1, 128, 28, 14])\n",
      "concat torch.Size([1, 384, 28, 14])\n",
      "#---------------------\n",
      "Output shape: torch.Size([1, 384, 28, 14])\n"
     ]
    }
   ],
   "source": [
    "d1, d2, d3 = 3,3,3\n",
    "\n",
    "x = torch.randn(1, 768, 28, 14)\n",
    "print(\"Input shape:\", x.shape)\n",
    "mdc_block = MDCBlock(in_channels, out_channels, d1, d2, d3)\n",
    "output = mdc_block(x)\n",
    "print(\"#---------------------\")\n",
    "print(\"Output shape:\", output.shape)  # Output shape will depend on the input size and parameters of the block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 768, 28, 14])\n",
      "x shape  torch.Size([1, 384, 28, 14])\n",
      "torch.Size([1, 128, 28, 14])\n",
      "torch.Size([1, 128, 28, 14])\n",
      "torch.Size([1, 128, 28, 14])\n",
      "concat torch.Size([1, 384, 28, 14])\n",
      "#---------------------\n",
      "Output shape: torch.Size([1, 384, 28, 14])\n"
     ]
    }
   ],
   "source": [
    "d1, d2, d3 = 1,3,3\n",
    "\n",
    "x = torch.randn(1, 768, 28, 14)\n",
    "print(\"Input shape:\", x.shape)\n",
    "mdc_block = MDCBlock(in_channels, out_channels, d1, d2, d3)\n",
    "output = mdc_block(x)\n",
    "print(\"#---------------------\")\n",
    "print(\"Output shape:\", output.shape)  # Output shape will depend on the input size and parameters of the block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MDCBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,  d1, d2, d3):\n",
    "        super(MDCBlock, self).__init__()\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        # Pre-Channel Mixer (Point-wise convolution)\n",
    "        self.pre_mixer = nn.Conv2d(in_channels, self.out_channels, kernel_size=1)\n",
    "\n",
    "        # Dilated Convolutional Layers\n",
    "        self.dcl1 = nn.Conv2d(self.out_channels//3,self.out_channels//3, kernel_size=3, dilation=d1, padding=d1)\n",
    "\t\t\t\t# dilation => d2\n",
    "        self.dcl2 = nn.Conv2d(self.out_channels//3, self.out_channels//3, kernel_size=3, dilation=d2, padding=d2)\n",
    "        # dilation => d3 \n",
    "        self.dcl3 = nn.Conv2d(self.out_channels//3, self.out_channels//3, kernel_size=3, dilation=d3, padding=d3)\n",
    "\n",
    "\n",
    "        # Post-Channel Mixer\n",
    "        self.post_mixer = nn.Sequential(\n",
    "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\t\t\t\t\n",
    "\t\t\t\t# channel wise concat x \n",
    "\t\n",
    "        # Pre-Channel Mixer\n",
    "        x = self.pre_mixer(x)\n",
    "        print(\"x shape \", x.shape)\n",
    "        #x shape  torch.Size([1, 64, 32, 32])\n",
    "        x1 = x[:,0:self.out_channels//3 * 1 ,:,:] \n",
    "        x2 = x[:,self.out_channels//3 * 1 : self.out_channels//3 * 2,:,:]\n",
    "        x3 = x[:,self.out_channels//3 * 2 : self.out_channels//3 * 3,:,:]\n",
    "\n",
    "        print(x1.shape)\n",
    "        print(x2.shape)\n",
    "        print(x3.shape)\n",
    "        # Dilated Convolutional Layers\n",
    "        dcl1_out = self.dcl1(x1)\n",
    "        dcl2_out = self.dcl2(x2)\n",
    "        dcl3_out = self.dcl3(x3)\n",
    "\n",
    "        # Concatenate the outputs along the channel dimension\n",
    "        x = torch.cat([dcl1_out, dcl2_out, dcl3_out], dim=1)\n",
    "\n",
    "        #print(\"concat\",x.shape)\n",
    "        # Post-Channel Mixer\n",
    "        x = self.post_mixer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 768, 28, 14])\n",
      "x shape  torch.Size([1, 768, 28, 14])\n",
      "torch.Size([1, 256, 28, 14])\n",
      "torch.Size([1, 256, 28, 14])\n",
      "torch.Size([1, 256, 28, 14])\n",
      "#---------------------\n",
      "Output shape: torch.Size([1, 768, 28, 14])\n"
     ]
    }
   ],
   "source": [
    "d1, d2, d3 = 3, 5, 7\n",
    "#x = torch.randn(1, in_channels, 896, 448)  # Example input tensor\n",
    "\n",
    "x = torch.randn(1, 768, 28, 14)\n",
    "print(\"Input shape:\", x.shape)\n",
    "\n",
    "MDC_Block_1 = MDCBlock(768,768,3,5,7)\n",
    "output = MDC_Block_1(x)\n",
    "print(\"#---------------------\")\n",
    "print(\"Output shape:\", output.shape)  # Output shape will depend on the input size and parameters of the block\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "8.tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
