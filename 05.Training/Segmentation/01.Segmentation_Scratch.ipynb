{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from albumentations import *\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from glob import glob\n",
    "import utils_rs\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aug():\n",
    "    trans_ = Compose([\n",
    "        # affine\n",
    "        VerticalFlip(p=0.5),\n",
    "\t\tHorizontalFlip(p=0.5),\n",
    "        RandomRotate90(p=0.5),\n",
    "        #RandomBrightnessContrast(p=0.5),\n",
    "    ])\n",
    "\n",
    "    return trans_ \n",
    "\n",
    "def build_transformer():\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transformer\n",
    "\n",
    "class building_dataset():\n",
    "    def __init__(self, img_dir,mask_dir, phase, tfms=get_aug()):\n",
    "        self.phase = phase\n",
    "\n",
    "        self.image_files = sorted(glob( os.path.join( img_dir , \"*.png\")) )\n",
    "        self.mask_files  = sorted(glob( os.path.join( mask_dir , \"*.png\")))\n",
    "\n",
    "        assert len(self.image_files) == len(self.mask_files)\n",
    "\n",
    "        self.IMAGE_SIZE = 224 #224 => 250\n",
    "        self.tfms = tfms\n",
    "\n",
    "        self.ISAID_PALETTE = {\n",
    "            0: (0, 0, 0), 1: (0, 0, 63), 2: (0, 63, 63), 3: (0, 63, 0), 4: (0, 63, 127),\n",
    "            5: (0, 63, 191), 6: (0, 63, 255), 7: (0, 127, 63), 8: (0, 127, 127),\n",
    "            9: (0, 0, 127), 10: (0, 0, 191), 11: (0, 0, 255), 12: (0, 191, 127),\n",
    "            13: (0, 127, 191), 14: (0, 127, 255), 15: (0, 100, 155)}\n",
    "\n",
    "        self.ISAID_CLASSES = ('background', 'ship', 'store_tank', 'baseball_diamond',\n",
    "            'tennis_court', 'basketball_court', 'Ground_Track_Field',\n",
    "            'Bridge', 'Large_Vehicle', 'Small_Vehicle', 'Helicopter',\n",
    "            'Swimming_pool', 'Roundabout', 'Soccer_ball_field', 'plane',\n",
    "            'Harbor')\n",
    "        \n",
    "        self.trans_ = Compose([\n",
    "                # affine\n",
    "                VerticalFlip(p=0.8),\n",
    "                HorizontalFlip(p=0.8),\n",
    "                RandomRotate90(p=0.8),\n",
    "                #RandomBrightnessContrast(p=0.5),\n",
    "                ])\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def build_transformer_normalize(self):\n",
    "      transformer = transforms.Compose([\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "      ])\n",
    "      return transformer\n",
    "\n",
    "    def convert_to_target_(self, mask_image, IMAGE_SIZE):\n",
    "        #print(mask_image.shape)\n",
    "        mask_image = np.asarray(mask_image)\n",
    "\n",
    "        canvas = np.zeros( (mask_image.shape[0],mask_image.shape[1]) ,  dtype=np.uint8)\n",
    "        for k,v in self.ISAID_PALETTE.items():\n",
    "            canvas[np.all(mask_image == v, axis=-1)] = k\n",
    "\n",
    "        #-------\n",
    "        #mask = np.argmax(canvas, axis=-1 )\n",
    "        #print(canvas.shape)\n",
    "\n",
    "        return canvas\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # image\n",
    "        image = cv2.imread( self.image_files[index] )\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, dsize=(self.IMAGE_SIZE,self.IMAGE_SIZE), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # mask\n",
    "        mask = cv2.imread( self.mask_files[index] )\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.resize(mask, dsize=(self.IMAGE_SIZE,self.IMAGE_SIZE), interpolation=cv2.INTER_NEAREST) # inter nearest\n",
    "        \n",
    "        # build normalize\n",
    "        normalizer = self.build_transformer_normalize()\n",
    "\n",
    "        if self.phase=='train':\n",
    "            \n",
    "            # aug \n",
    "            augmented = self.trans_(image=image,mask=mask)\n",
    "            image= augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "            # processing \n",
    "            image = normalizer(image)\n",
    "            mask = self.convert_to_target_(mask, self.IMAGE_SIZE)\n",
    "            mask = torch.from_numpy(mask).long()\n",
    "            \n",
    "            return image, mask\n",
    "    \n",
    "        elif self.phase=='val':\n",
    "          # normalize validation 할 때는 그냥 normalize 빼보자\n",
    "           image = normalizer(image)\n",
    "\n",
    "           mask = self.convert_to_target_2(mask_image, self.IMAGE_SIZE)\n",
    "           target = torch.from_numpy(mask).long()\n",
    "           return image, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for a, b in batch:\n",
    "        \n",
    "        images.append(a)\n",
    "        targets.append(b)\n",
    "    images = torch.stack(images, dim=0)\n",
    "    targets = torch.stack(targets, dim=0)\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/01.Models/04.SAM_fine/0.data/01.512_imgs\"\n",
    "mask_path = \"/mnt/hdd/eric/.tmp_ipy/15.Lab_Detection/01.Models/04.SAM_fine/0.data/02.512_masks\"\n",
    "\n",
    "tr_dataset = building_dataset(img_dir=img_path, mask_dir=mask_path, phase=\"train\", tfms=get_aug())\n",
    "val_dataset = building_dataset(img_dir=img_path,mask_dir=mask_path, phase=\"val\", tfms=get_aug())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"resnet152\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=16,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_metric():\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.CE_loss = nn.CrossEntropyLoss(reduction=\"mean\") # \"mean\" or \"sum\"\n",
    "\n",
    "    def __call__(self, pred, target):\n",
    "        # cross-entropy\n",
    "        loss1 = self.CE_loss(pred, target)\n",
    "        \n",
    "        # dice-coefficient\n",
    "        onehot_pred = F.one_hot(torch.argmax(pred, dim=1), num_classes=self.num_classes).permute(0, 3, 1, 2) \n",
    "        onehot_target = F.one_hot(target, num_classes=self.num_classes).permute(0, 3, 1, 2)\n",
    "        loss2 = self._get_dice_loss(onehot_pred, onehot_target)\n",
    "        \n",
    "        # total loss\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        # dice score\n",
    "        dice_coefficient = self._get_batch_dice_coefficient(onehot_pred, onehot_target)\n",
    "        return loss, dice_coefficient\n",
    "\n",
    "    def _get_dice_coeffient(self, pred, target):\n",
    "        set_inter = torch.dot(pred.reshape(-1).float(), target.reshape(-1).float())\n",
    "        set_sum = pred.sum() + target.sum()\n",
    "        if set_sum.item() == 0:\n",
    "            set_sum = 2 * set_inter\n",
    "        dice_coeff = (2 * set_inter) / (set_sum + 1e-9)\n",
    "        return dice_coeff\n",
    "\n",
    "    def _get_multiclass_dice_coefficient(self, pred, target):\n",
    "        dice = 0\n",
    "        for class_index in range(1, self.num_classes):\n",
    "            dice += self._get_dice_coeffient(pred[class_index], target[class_index])\n",
    "        return dice / (self.num_classes - 1)\n",
    "\n",
    "    def _get_batch_dice_coefficient(self, pred, target):\n",
    "        num_batch = pred.shape[0]\n",
    "        dice = 0\n",
    "        for batch_index in range(num_batch):\n",
    "            dice += self._get_multiclass_dice_coefficient(pred[batch_index], target[batch_index])\n",
    "        return dice / num_batch\n",
    "\n",
    "    def _get_dice_loss(self, pred, target):\n",
    "        return 1 - self._get_batch_dice_coefficient(pred, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "8.tmp.copied",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
